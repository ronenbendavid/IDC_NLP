{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Asi Assignment 4 - NER with BERT",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0d6414bd985844118181a31cf095f87b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_25493acb1f6548e7aeec21e9e85618ef",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_9607ff0ba4fe4dfa8cb11fa5ac12f322",
              "IPY_MODEL_efbda37b9b724776a26f84d038f9257b"
            ]
          }
        },
        "25493acb1f6548e7aeec21e9e85618ef": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9607ff0ba4fe4dfa8cb11fa5ac12f322": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_ed544ea4aa14484bb35bd4d167dc944c",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 213450,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 213450,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c90a753547bb46b98224ff023e1e9391"
          }
        },
        "efbda37b9b724776a26f84d038f9257b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_67f094c643084ba890806d1f282c5417",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 213k/213k [00:00&lt;00:00, 720kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_650d0a729fa043ffa43fa10e622ba66e"
          }
        },
        "ed544ea4aa14484bb35bd4d167dc944c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c90a753547bb46b98224ff023e1e9391": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "67f094c643084ba890806d1f282c5417": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "650d0a729fa043ffa43fa10e622ba66e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ea930700fc08474ea36dfb23939da033": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_bf50ab23372e4157a3419b9843dbcaf1",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_ebd2bb6672ea42668b9065d3e126de8c",
              "IPY_MODEL_04da986bbb554e4cb3e3fded7b63d03f"
            ]
          }
        },
        "bf50ab23372e4157a3419b9843dbcaf1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ebd2bb6672ea42668b9065d3e126de8c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_1febda59b34e47528b1ad47810297502",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 433,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 433,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_352e122f651346c3938a07e9b88a3dff"
          }
        },
        "04da986bbb554e4cb3e3fded7b63d03f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_f3975fe24918416d9144c559a8ff5021",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 433/433 [00:06&lt;00:00, 65.7B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_570c37e8623f493e82ff3fbac4141935"
          }
        },
        "1febda59b34e47528b1ad47810297502": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "352e122f651346c3938a07e9b88a3dff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f3975fe24918416d9144c559a8ff5021": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "570c37e8623f493e82ff3fbac4141935": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "43eb7ca2d82b4b88a909a05e0e05c94c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_8182744709de449f8b5f77fc757b5cfd",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_3b76a89687a246a194745f5a87d207b7",
              "IPY_MODEL_b027342c4f2e45b3991db2f10a52378b"
            ]
          }
        },
        "8182744709de449f8b5f77fc757b5cfd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3b76a89687a246a194745f5a87d207b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_0ee2a1b23dea4c6998efccd24061f214",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 435779157,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 435779157,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b830b8e0dfbd44b69ba3c7103f076306"
          }
        },
        "b027342c4f2e45b3991db2f10a52378b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_4e8f3e1d8eb840bab454737944ce9e45",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 436M/436M [00:06&lt;00:00, 67.6MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_71584bdd079942bfab1a89dc06ba6a39"
          }
        },
        "0ee2a1b23dea4c6998efccd24061f214": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b830b8e0dfbd44b69ba3c7103f076306": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4e8f3e1d8eb840bab454737944ce9e45": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "71584bdd079942bfab1a89dc06ba6a39": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ronenbendavid/IDC_NLP/blob/master/Copy_of_Asi_Assignment_4_NER_with_BERT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k-WJBimYDLJS",
        "colab_type": "text"
      },
      "source": [
        "# Assignment 4\n",
        "Training a neural named entity recognition (NER) tagger using BERT."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3enPCGBF8FlX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "654708f1-225b-4c3c-c5f0-829d6c96df7c"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print('version: {}, device: {}, device name: {}'.format(torch.__version__, device, torch.cuda.get_device_name(0)))\n",
        "\n",
        "model_path='model_ex4'"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "version: 1.6.0+cu101, device: cuda, device name: Tesla P100-PCIE-16GB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "woBMsSX9o2hH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 641
        },
        "outputId": "ce56e802-5153-4921-b994-d203bff1c2f8"
      },
      "source": [
        "!pip install transformers \n",
        "from transformers import BertModel, BertConfig"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/27/3c/91ed8f5c4e7ef3227b4119200fc0ed4b4fd965b1f0172021c25701087825/transformers-3.0.2-py3-none-any.whl (769kB)\n",
            "\r\u001b[K     |▍                               | 10kB 19.7MB/s eta 0:00:01\r\u001b[K     |▉                               | 20kB 6.0MB/s eta 0:00:01\r\u001b[K     |█▎                              | 30kB 7.4MB/s eta 0:00:01\r\u001b[K     |█▊                              | 40kB 8.1MB/s eta 0:00:01\r\u001b[K     |██▏                             | 51kB 6.6MB/s eta 0:00:01\r\u001b[K     |██▋                             | 61kB 7.1MB/s eta 0:00:01\r\u001b[K     |███                             | 71kB 7.5MB/s eta 0:00:01\r\u001b[K     |███▍                            | 81kB 8.2MB/s eta 0:00:01\r\u001b[K     |███▉                            | 92kB 7.7MB/s eta 0:00:01\r\u001b[K     |████▎                           | 102kB 7.9MB/s eta 0:00:01\r\u001b[K     |████▊                           | 112kB 7.9MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 122kB 7.9MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 133kB 7.9MB/s eta 0:00:01\r\u001b[K     |██████                          | 143kB 7.9MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 153kB 7.9MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 163kB 7.9MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 174kB 7.9MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 184kB 7.9MB/s eta 0:00:01\r\u001b[K     |████████                        | 194kB 7.9MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 204kB 7.9MB/s eta 0:00:01\r\u001b[K     |█████████                       | 215kB 7.9MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 225kB 7.9MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 235kB 7.9MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 245kB 7.9MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 256kB 7.9MB/s eta 0:00:01\r\u001b[K     |███████████                     | 266kB 7.9MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 276kB 7.9MB/s eta 0:00:01\r\u001b[K     |████████████                    | 286kB 7.9MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 296kB 7.9MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 307kB 7.9MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 317kB 7.9MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 327kB 7.9MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 337kB 7.9MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 348kB 7.9MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 358kB 7.9MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 368kB 7.9MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 378kB 7.9MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 389kB 7.9MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 399kB 7.9MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 409kB 7.9MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 419kB 7.9MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 430kB 7.9MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 440kB 7.9MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 450kB 7.9MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 460kB 7.9MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 471kB 7.9MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 481kB 7.9MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 491kB 7.9MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 501kB 7.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 512kB 7.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 522kB 7.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 532kB 7.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 542kB 7.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 552kB 7.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 563kB 7.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 573kB 7.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 583kB 7.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 593kB 7.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 604kB 7.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 614kB 7.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 624kB 7.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 634kB 7.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 645kB 7.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 655kB 7.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 665kB 7.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 675kB 7.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 686kB 7.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 696kB 7.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 706kB 7.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 716kB 7.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 727kB 7.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 737kB 7.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 747kB 7.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 757kB 7.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 768kB 7.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 778kB 7.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Collecting tokenizers==0.8.1.rc1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/40/d0/30d5f8d221a0ed981a186c8eb986ce1c94e3a6e87f994eae9f4aa5250217/tokenizers-0.8.1rc1-cp36-cp36m-manylinux1_x86_64.whl (3.0MB)\n",
            "\u001b[K     |████████████████████████████████| 3.0MB 23.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
            "Collecting sentencepiece!=0.1.92\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 46.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 53.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (1.15.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.6.20)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.16.0)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893260 sha256=c6c8b8ee38a47fb243e7e316e6cedbabc443fd8017513af88e5125bba12c0e63\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: tokenizers, sentencepiece, sacremoses, transformers\n",
            "Successfully installed sacremoses-0.0.43 sentencepiece-0.1.91 tokenizers-0.8.1rc1 transformers-3.0.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V5QSIEoyDdWh",
        "colab_type": "text"
      },
      "source": [
        "In this assignment you are required to build a full training and testing pipeline for a neural sequentail tagger for named entities, using BERT transformer, similar to assignment 3.\n",
        "\n",
        "The dataset that you will be working on is called ReCoNLL 2003, which is a corrected version of the CoNLL 2003 dataset: https://www.clips.uantwerpen.be/conll2003/ner/\n",
        "\n",
        "[Train data](https://drive.google.com/file/d/1hG66e_OoezzeVKho1w7ysyAx4yp0ShDz/view?usp=sharing)\n",
        "\n",
        "[Dev data](https://drive.google.com/file/d/1EAF-VygYowU1XknZhvzMi2CID65I127L/view?usp=sharing)\n",
        "\n",
        "[Test data](https://drive.google.com/file/d/16gug5wWnf06JdcBXQbcICOZGZypgr4Iu/view?usp=sharing)\n",
        "\n",
        "As you can see, the annotated texts are labeled according to the IOB annotation scheme, for 3 entity types: Person, Organization, Location."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ul2Y3vuPoV8",
        "colab_type": "text"
      },
      "source": [
        "***(Already done in Assignment 3, so you may copy and paste it here)*** Write a funtion for reading the data from a single file (of the ones that are provided above). The function recieves a filepath and then it encodes every sentence individually using a pair of lists, one list contains the words and one list contains the tags. Each list pair will be added to a general list (data), which will be returned back from the function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "prgzgtt8Jw4Y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "5fbc1a72-8778-4998-fafe-7fddfa365883"
      },
      "source": [
        "import requests\n",
        "import re\n",
        "\n",
        "tag_values = set()\n",
        "def read_data(filepath):\n",
        "    sentences = []\n",
        "    labels = []\n",
        "\n",
        "    result = re.compile(\".*drive.google.com/file/d/([^/]*)/.*\").match(filepath)\n",
        "    if result:\n",
        "      filepath = 'https://docs.google.com/uc?export=download&id={}'.format(result.group(1))\n",
        "    print(filepath)\n",
        "\n",
        "    response = requests.get(filepath)\n",
        "    words = []\n",
        "    tags = []\n",
        "\n",
        "    for line in response.text.split('\\n'):\n",
        "        if not line:\n",
        "            if len(words) > 0:\n",
        "                sentences.append(words)\n",
        "                labels.append(tags)\n",
        "                tag_values.update(tags)\n",
        "            words = []\n",
        "            tags = []\n",
        "        else:\n",
        "            line = line.strip().split()\n",
        "            words.append(line[0])\n",
        "            tags.append(line[1])\n",
        "\n",
        "    return sentences, labels\n",
        "\n",
        "train_s, train_l = read_data('https://drive.google.com/file/d/1hG66e_OoezzeVKho1w7ysyAx4yp0ShDz/view?usp=sharing')\n",
        "dev_s, dev_l = read_data('https://drive.google.com/file/d/1EAF-VygYowU1XknZhvzMi2CID65I127L/view?usp=sharing')\n",
        "test_s, test_l = read_data('https://drive.google.com/file/d/16gug5wWnf06JdcBXQbcICOZGZypgr4Iu/view?usp=sharing')\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "https://docs.google.com/uc?export=download&id=1hG66e_OoezzeVKho1w7ysyAx4yp0ShDz\n",
            "https://docs.google.com/uc?export=download&id=1EAF-VygYowU1XknZhvzMi2CID65I127L\n",
            "https://docs.google.com/uc?export=download&id=16gug5wWnf06JdcBXQbcICOZGZypgr4Iu\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DfJ0wRr3_n-6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tag_values = list(tag_values)\n",
        "tag_values.append(\"PAD\")\n",
        "list.sort(tag_values) # sort so we can reuse saved models\n",
        "tag2idx = {t: i for i, t in enumerate(tag_values)}"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IuGwk6OwRWGS",
        "colab_type": "text"
      },
      "source": [
        "Use Huggingface transformers:\n",
        "https://github.com/huggingface/transformers\n",
        "\n",
        "to process the data and train a BERT model (with a Linear layer on top) for NER.\n",
        "\n",
        "Then, evaluate it on the Dev and Test data and report on results."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gTNmBU6hycZl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "8390c1eb-561c-4712-a666-57821e2c525f"
      },
      "source": [
        "print(tag2idx)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'B-LOC': 0, 'B-ORG': 1, 'B-PER': 2, 'I-LOC': 3, 'I-ORG': 4, 'I-PER': 5, 'O': 6, 'PAD': 7}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZF8U64d4-0Oj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 531
        },
        "outputId": "d532d658-c0e9-46ea-c9a4-f2655f5c4467"
      },
      "source": [
        "for token, label in zip(train_s[3], train_l[3]):\n",
        "    print(\"{}\\t{}\".format(label, token))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "B-LOC\tEngland\n",
            "O\twere\n",
            "O\tall\n",
            "O\tout\n",
            "O\tfor\n",
            "O\t326\n",
            "O\tin\n",
            "O\ttheir\n",
            "O\tfirst\n",
            "O\tinnings\n",
            "O\ton\n",
            "O\tthe\n",
            "O\tsecond\n",
            "O\tday\n",
            "O\tof\n",
            "O\tthe\n",
            "O\tthird\n",
            "O\tand\n",
            "O\tfinal\n",
            "O\ttest\n",
            "O\tagainst\n",
            "B-LOC\tPakistan\n",
            "O\tat\n",
            "B-LOC\tThe\n",
            "I-LOC\tOval\n",
            "O\ton\n",
            "O\tFriday\n",
            "O\t.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PHvVAI6U-3DY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "ec74f696-0d20-4af0-86aa-f6f4f0c189a0"
      },
      "source": [
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from transformers import BertTokenizer, BertConfig\n",
        "\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "torch.__version__"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'1.6.0+cu101'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xvnx4hPw_DKk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MAX_LEN = 75\n",
        "bs = 32\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Bshqbzq_Q-q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67,
          "referenced_widgets": [
            "0d6414bd985844118181a31cf095f87b",
            "25493acb1f6548e7aeec21e9e85618ef",
            "9607ff0ba4fe4dfa8cb11fa5ac12f322",
            "efbda37b9b724776a26f84d038f9257b",
            "ed544ea4aa14484bb35bd4d167dc944c",
            "c90a753547bb46b98224ff023e1e9391",
            "67f094c643084ba890806d1f282c5417",
            "650d0a729fa043ffa43fa10e622ba66e"
          ]
        },
        "outputId": "35c8d1b8-b2a8-4490-a3ca-4ef8dfb1bc37"
      },
      "source": [
        "import os\n",
        "if os.path.exists('{}/vocab.txt'.format(model_path)):\n",
        "    tokenizer = BertTokenizer.from_pretrained('bert-base-cased', do_lower_case=False).from_pretrained(model_path)\n",
        "else:\n",
        "    tokenizer = BertTokenizer.from_pretrained('bert-base-cased', do_lower_case=False)    "
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0d6414bd985844118181a31cf095f87b",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=213450.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jJjT_yAL_VRq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tokenize_and_preserve_labels(sentence, labels):\n",
        "    tokenized_sentence = []\n",
        "    tokenized_labels = []\n",
        "\n",
        "    for word, label in zip(sentence, labels):\n",
        "\n",
        "        # Tokenize the word and count # of subwords the word is broken into\n",
        "        tokenized_word = tokenizer.tokenize(word)\n",
        "        n_subwords = len(tokenized_word)\n",
        "\n",
        "        # Add the tokenized word to the final tokenized word list\n",
        "        tokenized_sentence.extend(tokenized_word)\n",
        "\n",
        "        # Add the same label to the new list of labels `n_subwords` times\n",
        "        tokenized_labels.extend([label] * n_subwords)\n",
        "\n",
        "    return tokenized_sentence, tokenized_labels"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-z01E2RD_Y8x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tr_tokenized_texts_and_labels = [\n",
        "    tokenize_and_preserve_labels(sent, labs)\n",
        "    for sent, labs in zip(train_s, train_l)\n",
        "]\n",
        "\n",
        "val_tokenized_texts_and_labels = [\n",
        "    tokenize_and_preserve_labels(sent, labs)\n",
        "    for sent, labs in zip(dev_s, dev_l)\n",
        "]\n",
        "\n",
        "test_tokenized_texts_and_labels = [\n",
        "    tokenize_and_preserve_labels(sent, labs)\n",
        "    for sent, labs in zip(test_s, test_l)\n",
        "]"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2FMiMh8JSW5q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tr_tokenized_texts = [token_label_pair[0] for token_label_pair in tr_tokenized_texts_and_labels]\n",
        "tr_labels = [token_label_pair[1] for token_label_pair in tr_tokenized_texts_and_labels]\n",
        "\n",
        "val_tokenized_texts = [token_label_pair[0] for token_label_pair in val_tokenized_texts_and_labels]\n",
        "val_labels = [token_label_pair[1] for token_label_pair in val_tokenized_texts_and_labels]"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uIrtXztPSW8n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tr_inputs = pad_sequences([tokenizer.convert_tokens_to_ids(txt) for txt in tr_tokenized_texts],\n",
        "                          maxlen=MAX_LEN, dtype=\"long\", value=0.0,\n",
        "                          truncating=\"post\", padding=\"post\")\n",
        "\n",
        "val_inputs = pad_sequences([tokenizer.convert_tokens_to_ids(txt) for txt in val_tokenized_texts],\n",
        "                          maxlen=MAX_LEN, dtype=\"long\", value=0.0,\n",
        "                          truncating=\"post\", padding=\"post\")\n"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QCOrV_PfSW_W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tr_tags = pad_sequences([[tag2idx.get(l) for l in lab] for lab in tr_labels],\n",
        "                     maxlen=MAX_LEN, value=tag2idx[\"PAD\"], padding=\"post\",\n",
        "                     dtype=\"long\", truncating=\"post\")\n",
        "\n",
        "val_tags = pad_sequences([[tag2idx.get(l) for l in lab] for lab in val_labels],\n",
        "                     maxlen=MAX_LEN, value=tag2idx[\"PAD\"], padding=\"post\",\n",
        "                     dtype=\"long\", truncating=\"post\")\n"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Q1s_aKsSXB-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tr_masks = [[float(i != 0.0) for i in ii] for ii in tr_inputs]\n",
        "\n",
        "val_masks = [[float(i != 0.0) for i in ii] for ii in val_inputs]\n"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZJg_bW1-SXEn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tr_inputs = torch.tensor(tr_inputs)\n",
        "tr_tags = torch.tensor(tr_tags)\n",
        "tr_masks = torch.tensor(tr_masks)\n",
        "\n",
        "val_inputs = torch.tensor(val_inputs)\n",
        "val_tags = torch.tensor(val_tags)\n",
        "val_masks = torch.tensor(val_masks)\n"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dBAkh4MgSXHG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data = TensorDataset(tr_inputs, tr_masks, tr_tags)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=bs)\n",
        "\n",
        "valid_data = TensorDataset(val_inputs, val_masks, val_tags)\n",
        "valid_sampler = SequentialSampler(valid_data)\n",
        "valid_dataloader = DataLoader(valid_data, sampler=valid_sampler, batch_size=bs)\n"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bkpm617SSev2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "2ddaaa2c-b9d9-4c85-b847-69e326a4f1f0"
      },
      "source": [
        "import transformers\n",
        "from transformers import BertForTokenClassification, AdamW\n",
        "\n",
        "transformers.__version__\n"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'3.0.2'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0welZ0zVSeyl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 230,
          "referenced_widgets": [
            "ea930700fc08474ea36dfb23939da033",
            "bf50ab23372e4157a3419b9843dbcaf1",
            "ebd2bb6672ea42668b9065d3e126de8c",
            "04da986bbb554e4cb3e3fded7b63d03f",
            "1febda59b34e47528b1ad47810297502",
            "352e122f651346c3938a07e9b88a3dff",
            "f3975fe24918416d9144c559a8ff5021",
            "570c37e8623f493e82ff3fbac4141935",
            "43eb7ca2d82b4b88a909a05e0e05c94c",
            "8182744709de449f8b5f77fc757b5cfd",
            "3b76a89687a246a194745f5a87d207b7",
            "b027342c4f2e45b3991db2f10a52378b",
            "0ee2a1b23dea4c6998efccd24061f214",
            "b830b8e0dfbd44b69ba3c7103f076306",
            "4e8f3e1d8eb840bab454737944ce9e45",
            "71584bdd079942bfab1a89dc06ba6a39"
          ]
        },
        "outputId": "ecc6fab4-4de3-4743-e6ca-13aa2cf51f61"
      },
      "source": [
        "import os\n",
        "\n",
        "if os.path.exists('{}/vocab.txt'.format(model_path)):\n",
        "    model = BertForTokenClassification.from_pretrained(\n",
        "        \"bert-base-cased\",\n",
        "        num_labels=len(tag2idx),\n",
        "        output_attentions = False,\n",
        "        output_hidden_states = False\n",
        "    ).from_pretrained(model_path)\n",
        "    model.cuda()\n",
        "    model.eval()\n",
        "else:\n",
        "    model = BertForTokenClassification.from_pretrained(\n",
        "        \"bert-base-cased\",\n",
        "        num_labels=len(tag2idx),\n",
        "        output_attentions = False,\n",
        "        output_hidden_states = False\n",
        "    )\n",
        "    model.cuda()    "
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ea930700fc08474ea36dfb23939da033",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=433.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "43eb7ca2d82b4b88a909a05e0e05c94c",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=435779157.0, style=ProgressStyle(descri…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForTokenClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l-H93jS6Se1F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "FULL_FINETUNING = True\n",
        "if FULL_FINETUNING:\n",
        "    param_optimizer = list(model.named_parameters())\n",
        "    no_decay = ['bias', 'gamma', 'beta']\n",
        "    optimizer_grouped_parameters = [\n",
        "        {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n",
        "         'weight_decay_rate': 0.01},\n",
        "        {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n",
        "         'weight_decay_rate': 0.0}\n",
        "    ]\n",
        "else:\n",
        "    param_optimizer = list(model.classifier.named_parameters())\n",
        "    optimizer_grouped_parameters = [{\"params\": [p for n, p in param_optimizer]}]\n",
        "\n",
        "optimizer = AdamW(\n",
        "    optimizer_grouped_parameters,\n",
        "    lr=3e-5,\n",
        "    eps=1e-8\n",
        ")\n"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zRHcdC1WthNP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "epochs = 10\n",
        "max_grad_norm = 1.0\n",
        "\n",
        "# Total number of training steps is number of batches * number of epochs.\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "# Create the learning rate scheduler.\n",
        "scheduler = get_linear_schedule_with_warmup(\n",
        "    optimizer,\n",
        "    num_warmup_steps=0,\n",
        "    num_training_steps=total_steps\n",
        ")"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "leJal_quSe8N",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "outputId": "8bc693ef-824f-48dd-ac39-35e5bd41577e"
      },
      "source": [
        "import numpy as np\n",
        "from tqdm import tqdm, trange\n",
        "!pip install seqeval\n",
        "from seqeval.metrics import f1_score, accuracy_score\n",
        "\n",
        "def train():\n",
        "\n",
        "    ## Store the average loss after each epoch so we can plot them.\n",
        "    loss_values, validation_loss_values = [], []\n",
        "\n",
        "    for _ in trange(epochs, desc=\"Epoch\"):\n",
        "        # ========================================\n",
        "        #               Training\n",
        "        # ========================================\n",
        "        # Perform one full pass over the training set.\n",
        "\n",
        "        # Put the model into training mode.\n",
        "        model.train()\n",
        "        # Reset the total loss for this epoch.\n",
        "        total_loss = 0\n",
        "\n",
        "        # Training loop\n",
        "        for step, batch in enumerate(train_dataloader):\n",
        "            # add batch to gpu\n",
        "            batch = tuple(t.to(device) for t in batch)\n",
        "            b_input_ids, b_input_mask, b_labels = batch\n",
        "            # Always clear any previously calculated gradients before performing a backward pass.\n",
        "            model.zero_grad()\n",
        "            # forward pass\n",
        "            # This will return the loss (rather than the model output)\n",
        "            # because we have provided the `labels`.\n",
        "            outputs = model(b_input_ids, token_type_ids=None,\n",
        "                            attention_mask=b_input_mask, labels=b_labels)\n",
        "            # get the loss\n",
        "            loss = outputs[0]\n",
        "            # Perform a backward pass to calculate the gradients.\n",
        "            loss.backward()\n",
        "            # track train loss\n",
        "            total_loss += loss.item()\n",
        "            # Clip the norm of the gradient\n",
        "            # This is to help prevent the \"exploding gradients\" problem.\n",
        "            torch.nn.utils.clip_grad_norm_(parameters=model.parameters(), max_norm=max_grad_norm)\n",
        "            # update parameters\n",
        "            optimizer.step()\n",
        "            # Update the learning rate.\n",
        "            scheduler.step()\n",
        "\n",
        "        # Calculate the average loss over the training data.\n",
        "        avg_train_loss = total_loss / len(train_dataloader)\n",
        "        print(\"Average train loss: {}\".format(avg_train_loss))\n",
        "\n",
        "        # Store the loss value for plotting the learning curve.\n",
        "        loss_values.append(avg_train_loss)\n",
        "\n",
        "\n",
        "        # ========================================\n",
        "        #               Validation\n",
        "        # ========================================\n",
        "        # After the completion of each training epoch, measure our performance on\n",
        "        # our validation set.\n",
        "\n",
        "        # Put the model into evaluation mode\n",
        "        model.eval()\n",
        "        # Reset the validation loss for this epoch.\n",
        "        eval_loss, eval_accuracy = 0, 0\n",
        "        nb_eval_steps, nb_eval_examples = 0, 0\n",
        "        predictions , true_labels = [], []\n",
        "        for batch in valid_dataloader:\n",
        "            batch = tuple(t.to(device) for t in batch)\n",
        "            b_input_ids, b_input_mask, b_labels = batch\n",
        "\n",
        "            # Telling the model not to compute or store gradients,\n",
        "            # saving memory and speeding up validation\n",
        "            with torch.no_grad():\n",
        "                # Forward pass, calculate logit predictions.\n",
        "                # This will return the logits rather than the loss because we have not provided labels.\n",
        "                outputs = model(b_input_ids, token_type_ids=None,\n",
        "                                attention_mask=b_input_mask, labels=b_labels)\n",
        "            # Move logits and labels to CPU\n",
        "            logits = outputs[1].detach().cpu().numpy()\n",
        "            label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "            # Calculate the accuracy for this batch of test sentences.\n",
        "            eval_loss += outputs[0].mean().item()\n",
        "            predictions.extend([list(p) for p in np.argmax(logits, axis=2)])\n",
        "            true_labels.extend(label_ids)\n",
        "\n",
        "        eval_loss = eval_loss / len(valid_dataloader)\n",
        "        validation_loss_values.append(eval_loss)\n",
        "        print(\"Validation loss: {}\".format(eval_loss))\n",
        "        pred_tags = [tag_values[p_i] for p, l in zip(predictions, true_labels)\n",
        "                                     for p_i, l_i in zip(p, l) if tag_values[l_i] != \"PAD\"]\n",
        "        valid_tags = [tag_values[l_i] for l in true_labels\n",
        "                                      for l_i in l if tag_values[l_i] != \"PAD\"]\n",
        "        print(\"Validation Accuracy: {}\".format(accuracy_score(pred_tags, valid_tags) if valid_tags else \"Unknown\"))\n",
        "        print(\"Validation F1-Score: {}\".format(f1_score(pred_tags, valid_tags) if valid_tags else \"Unknown\"))\n",
        "        print()\n",
        "        \n",
        "    return loss_values, validation_loss_values\n"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting seqeval\n",
            "  Downloading https://files.pythonhosted.org/packages/34/91/068aca8d60ce56dd9ba4506850e876aba5e66a6f2f29aa223224b50df0de/seqeval-0.0.12.tar.gz\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from seqeval) (1.18.5)\n",
            "Requirement already satisfied: Keras>=2.2.4 in /usr/local/lib/python3.6/dist-packages (from seqeval) (2.4.3)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from Keras>=2.2.4->seqeval) (2.10.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from Keras>=2.2.4->seqeval) (3.13)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from Keras>=2.2.4->seqeval) (1.4.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from h5py->Keras>=2.2.4->seqeval) (1.15.0)\n",
            "Building wheels for collected packages: seqeval\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-0.0.12-cp36-none-any.whl size=7424 sha256=758c98a930b53c7e72f84bac2a69b25bd209b19dad0ae3abe763d0248dd1966b\n",
            "  Stored in directory: /root/.cache/pip/wheels/4f/32/0a/df3b340a82583566975377d65e724895b3fad101a3fb729f68\n",
            "Successfully built seqeval\n",
            "Installing collected packages: seqeval\n",
            "Successfully installed seqeval-0.0.12\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Loi0WV0rSe-u",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "1ff51dcf-177c-4854-e75f-8e6c079301bb"
      },
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "def evaluate(loss_values, validation_loss_values):\n",
        "    # Use plot styling from seaborn.\n",
        "    sns.set(style='darkgrid')\n",
        "\n",
        "    # Increase the plot size and font size.\n",
        "    sns.set(font_scale=1.5)\n",
        "    plt.rcParams[\"figure.figsize\"] = (12,6)\n",
        "\n",
        "    # Plot the learning curve.\n",
        "    plt.plot(loss_values, 'b-o', label=\"training loss\")\n",
        "    plt.plot(validation_loss_values, 'r-o', label=\"validation loss\")\n",
        "\n",
        "    # Label the plot.\n",
        "    plt.title(\"Learning curve\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.legend()\n",
        "\n",
        "    plt.show()\n"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kJh3Le55SnJ9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        },
        "outputId": "5dea563e-e2f3-4ede-98de-fc5ba92b1df4"
      },
      "source": [
        "import os\n",
        "\n",
        "\n",
        "## Store the average loss after each epoch so we can plot them.\n",
        "loss_values, validation_loss_values = [], []\n",
        "\n",
        "if not os.path.exists('{}/vocab.txt'.format(model_path)):\n",
        "    loss_values, validation_loss_values = train()\n",
        "    evaluate(loss_values, validation_loss_values)\n",
        "    model.save_pretrained(model_path)  # save\n",
        "    tokenizer.save_pretrained(model_path)  # save\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\rEpoch:   0%|          | 0/10 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Average train loss: 0.7072655910795386\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rEpoch:  10%|█         | 1/10 [00:15<02:23, 15.98s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation loss: 0.2838880755007267\n",
            "Validation Accuracy: 0.9054586381541925\n",
            "Validation F1-Score: 0.6566347469220246\n",
            "\n",
            "Average train loss: 0.21664703434163873\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rEpoch:  20%|██        | 2/10 [00:31<02:06, 15.87s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation loss: 0.18476969748735428\n",
            "Validation Accuracy: 0.9365972613018195\n",
            "Validation F1-Score: 0.7493087557603687\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YTiFcCJxSnMs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "def analyze_sentence(sentence):\n",
        "    tokenized_sentence = tokenizer.encode(sentence)\n",
        "    input_ids = torch.tensor([tokenized_sentence]).cuda()\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        output = model(input_ids)\n",
        "    label_indices = np.argmax(output[0].to('cpu').numpy(), axis=2)\n",
        "\n",
        "    # join bpe split tokens\n",
        "    tokens = tokenizer.convert_ids_to_tokens(input_ids.to('cpu').numpy()[0])\n",
        "    new_tokens, new_labels = [], []\n",
        "    for token, label_idx in zip(tokens, label_indices[0]):\n",
        "        if token.startswith(\"##\"):\n",
        "            new_tokens[-1] = new_tokens[-1] + token[2:]\n",
        "        else:\n",
        "            new_labels.append(tag_values[label_idx])\n",
        "            new_tokens.append(token)\n",
        "\n",
        "    return new_tokens, new_labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mjAXLVK-SnPU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def align_sentence_labels(sentence, labels):\n",
        "    tokenized_sentence = []\n",
        "    tokenized_labels = []\n",
        "\n",
        "    for word, label in zip(sentence, labels):\n",
        "\n",
        "        # Tokenize the word and count # of subwords the word is broken into\n",
        "        tokenized_word = tokenizer.tokenize(word)\n",
        "        n_subwords = len(tokenized_word)\n",
        "\n",
        "        # Add the tokenized word to the final tokenized word list\n",
        "        tokenized_sentence.extend(tokenized_word)\n",
        "\n",
        "        # Add the same label to the new list of labels `n_subwords` times\n",
        "        tokenized_labels.extend([label] * n_subwords)\n",
        "\n",
        "        new_tokens, new_labels = [], []\n",
        "        for token, label in zip(tokenized_sentence, tokenized_labels):\n",
        "            if token.startswith(\"##\"):\n",
        "                new_tokens[-1] = new_tokens[-1] + token[2:]\n",
        "            else:\n",
        "                new_labels.append(label)\n",
        "                new_tokens.append(token)\n",
        "\n",
        "    return new_tokens, new_labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h6RtPgGUStf4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# test_sentence = \"\"\"\n",
        "# Mr. Trump’s tweets began just moments after a Fox News report by Mike Tobin, a \n",
        "# reporter for the network, about protests in Minnesota and elsewhere. \n",
        "# \"\"\"\n",
        "\n",
        "test_sentence = \"\"\"\n",
        "This is Assaf Sinvani notebook. \n",
        "it's part of the preparation for the NLP course in the IDC, Herzelia Interdisciplinary Center\n",
        "\"\"\"\n",
        "\n",
        "# test_sentence = \"\"\"\n",
        "# So, I would like to fly out sometime tonight and fly back in the evening in 4 days.\n",
        "# From I’m looking to go to Denver. I’m flying out of San Francisco.\n",
        "# \"\"\"\n",
        "\n",
        "# test_sentence = \"\"\"\n",
        "# I would like to book a room in the Park Hyatt Aviara Resort and it costs $279 per night.\n",
        "# It’s rated 4.8 stars. It offers an 18-hole golf course, an outdoor pool & tennis courts plus a spa & fine dining.\n",
        "# \"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DRXyRyhJStir",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 479
        },
        "outputId": "d17a3b75-3293-4f15-9f65-18ce9092086e"
      },
      "source": [
        "new_tokens, new_labels = analyze_sentence(test_sentence)\n",
        "for token, label in zip(new_tokens, new_labels):\n",
        "    print(\"{}\\t{}\".format(label, token))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "O\t[CLS]\n",
            "O\tThis\n",
            "O\tis\n",
            "B-PER\tAssaf\n",
            "I-PER\tSinvani\n",
            "O\tnotebook\n",
            "O\t.\n",
            "O\tit\n",
            "O\t'\n",
            "O\ts\n",
            "O\tpart\n",
            "O\tof\n",
            "O\tthe\n",
            "O\tpreparation\n",
            "O\tfor\n",
            "O\tthe\n",
            "B-ORG\tNLP\n",
            "O\tcourse\n",
            "O\tin\n",
            "O\tthe\n",
            "B-LOC\tIDC\n",
            "O\t,\n",
            "B-LOC\tHerzelia\n",
            "I-ORG\tInterdisciplinary\n",
            "I-ORG\tCenter\n",
            "O\t[SEP]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RkDS2TiqStls",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "def evaluate_dataset(model, sentences, labels):\n",
        "    y_true = np.array([])\n",
        "    y_pred = np.array([])\n",
        "\n",
        "    # build array for true labels and predicted labels\n",
        "    for (sentence, labels) in zip(sentences, labels):\n",
        "        _, pred_labels = analyze_sentence(sentence)\n",
        "\n",
        "        y_true = np.append(y_true, [tag2idx[l] for l in labels])\n",
        "        y_pred = np.append(y_pred, [tag2idx[l] for l in pred_labels[1:-1]])\n",
        "        \n",
        "\n",
        "    # use sklearn to calculate precision and recall for every label\n",
        "    report = classification_report(y_true, y_pred, labels=list(tag2idx.values()), target_names=list(tag2idx.keys()), digits=4, output_dict=True, zero_division=False)\n",
        "    precision = [report[label]['precision'] for label in tag2idx.keys()]\n",
        "    recall = [report[label]['recall'] for label in tag2idx.keys()]\n",
        "\n",
        "    # use sklearn to calculate precision and recall for all labels except O\n",
        "    report = classification_report(y_true != tag2idx['O'], y_pred != tag2idx['O'], target_names=['O', 'OTHER'], digits=4, output_dict=True)\n",
        "    precision.append(report['OTHER']['precision'])\n",
        "    recall.append(report['OTHER']['recall'])\n",
        "\n",
        "    return precision, recall\n",
        "\n",
        "\n",
        "def evaluate_model(model):\n",
        "    precision_dev, recall_dev = evaluate_dataset(model, dev_s, dev_l)\n",
        "    precision_test, recall_test = evaluate_dataset(model, test_s, test_l)\n",
        "\n",
        "    rows = ['precision dev', 'precision test', 'recall dev', 'recall test']\n",
        "    columns = list(tag2idx.keys())\n",
        "    columns.append('Not O')\n",
        "\n",
        "    df = pd.DataFrame(np.array([precision_dev, precision_test, recall_dev, recall_test]), index=rows, columns=columns)\n",
        "    print(df)\n",
        "\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_HPVIwKqStqT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "outputId": "0de38880-2c26-45c7-aa1e-ccbe342d716f"
      },
      "source": [
        "pd.options.display.max_columns = None\n",
        "pd.options.display.width = 1000\n",
        "\n",
        "evaluate_model(model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                   B-LOC     B-ORG     B-PER     I-LOC     I-ORG     I-PER         O  PAD     Not O\n",
            "precision dev   0.848649  0.813725  0.772277  0.928571  0.948052  0.900826  0.939543  0.0  0.928673\n",
            "precision test  0.811111  0.882653  0.823370  0.911111  0.891473  0.917051  0.934902  0.0  0.931559\n",
            "recall dev      0.857923  0.494048  0.780000  0.565217  0.629310  0.694268  0.983850  0.0  0.768595\n",
            "recall test     0.851312  0.494286  0.698157  0.773585  0.575000  0.672297  0.986295  0.0  0.730907\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y1KNyvQsvDma",
        "colab_type": "text"
      },
      "source": [
        "10 Epochs\n",
        "```\n",
        "B-LOC     B-ORG     B-PER     I-LOC     I-ORG     I-PER         O  PAD     Not O\n",
        "precision dev   0.747664  0.849057  0.776119  1.000000  0.948052  0.911111  0.947187  0.0  0.912517\n",
        "precision test  0.713942  0.810811  0.815013  0.967742  0.892308  0.900862  0.940488  0.0  0.903846\n",
        "recall dev      0.874317  0.535714  0.780000  0.434783  0.629310  0.783439  0.979005  0.0  0.800472\n",
        "recall test     0.865889  0.514286  0.700461  0.566038  0.580000  0.706081  0.979443  0.0  0.757160\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z8nl9wPWvcKi",
        "colab_type": "text"
      },
      "source": [
        "25 Epochs\n",
        "```\n",
        "                   B-LOC     B-ORG     B-PER     I-LOC     I-ORG     I-PER         O  PAD     Not O\n",
        "precision dev   0.848649  0.813725  0.772277  0.928571  0.948052  0.900826  0.939543  0.0  0.928673\n",
        "precision test  0.811111  0.882653  0.823370  0.911111  0.891473  0.917051  0.934902  0.0  0.931559\n",
        "recall dev      0.857923  0.494048  0.780000  0.565217  0.629310  0.694268  0.983850  0.0  0.768595\n",
        "recall test     0.851312  0.494286  0.698157  0.773585  0.575000  0.672297  0.986295  0.0  0.730907\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jxaESRoco6bV",
        "colab_type": "text"
      },
      "source": [
        "**Good luck!**"
      ]
    }
  ]
}