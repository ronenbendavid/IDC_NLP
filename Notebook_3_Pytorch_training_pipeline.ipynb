{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Notebook 3 - Pytorch training pipeline",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ronenbendavid/IDC_NLP/blob/master/Notebook_3_Pytorch_training_pipeline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jla2Yq63V5Wj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import random"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nub3OtKEJzaz",
        "colab_type": "text"
      },
      "source": [
        "# Creating a simple network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "prgzgtt8Jw4Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Defining sizes\n",
        "input_size = 10\n",
        "hidden_size = 5\n",
        "output_size = 1\n",
        "batch_size = 10\n",
        "\n",
        "# Constructing the network\n",
        "model = nn.Sequential(nn.Linear(input_size, hidden_size),\n",
        "                     nn.Sigmoid(),\n",
        "                     nn.Linear(hidden_size, output_size),\n",
        "                     nn.Sigmoid())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iIpbLdIJMq3N",
        "colab_type": "code",
        "outputId": "a46094b0-1d7c-4546-afd9-d81ce89fc4a2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "# Let's work with some fake data\n",
        "\n",
        "X = torch.randn(batch_size, input_size)\n",
        "print(X)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 0.3167, -1.4224,  0.5311,  0.4999, -1.1371,  1.4332, -0.9751, -0.0781,\n",
            "         -0.7610,  0.0699],\n",
            "        [-1.4307,  0.2213, -2.3601,  0.0199,  0.3128, -0.1287,  0.0976,  0.5705,\n",
            "          1.3391, -1.5107],\n",
            "        [ 0.5193, -0.2806, -1.6100,  0.3186,  0.9829, -2.0859,  1.5738,  0.0079,\n",
            "         -0.5001,  0.5751],\n",
            "        [ 0.1445,  0.5893,  0.1728, -0.2579, -0.1061,  0.0096,  0.3796,  0.4193,\n",
            "         -1.2806,  0.7602],\n",
            "        [-1.0250, -1.4276,  0.5248, -0.7152, -1.5114, -1.3619,  1.0585,  0.2329,\n",
            "          0.5783,  0.1718],\n",
            "        [-0.2436,  0.3063,  0.3667,  0.3956, -1.5452,  0.3507, -0.3077, -0.9435,\n",
            "         -1.9594,  0.4384],\n",
            "        [ 1.6515,  0.8769, -0.3714, -0.4306, -0.3306, -0.4618, -2.2473, -1.9754,\n",
            "         -0.2124,  1.0439],\n",
            "        [-0.2000, -1.5061,  0.6109,  0.1228, -0.9682,  0.9821, -0.4286, -0.8627,\n",
            "         -1.8579,  0.2381],\n",
            "        [-0.6467,  1.3112, -1.5943, -0.0978, -0.0285, -0.6983,  0.4668, -0.1474,\n",
            "         -1.5211,  0.8229],\n",
            "        [-1.2463, -0.4835, -0.5914,  0.4165, -1.4929, -0.0838, -2.5329, -0.0565,\n",
            "         -0.5701, -0.5219]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ifmtf6FSuYHE",
        "colab_type": "code",
        "outputId": "9fb3cff2-3f34-46f3-fc80-663674214ffe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "y = torch.randint(0, 2, (batch_size, output_size))\n",
        "y = y.type(torch.FloatTensor)\n",
        "print(y)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bHCoqKw2QWAj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define loss function\n",
        "\n",
        "criterion = torch.nn.MSELoss()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2CqH4vUwQnOT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define the optimizer\n",
        "\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qi4H9mxLQ-Xl",
        "colab_type": "code",
        "outputId": "8ce7097e-6a72-48fc-87e4-6737ec3cfe83",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17017
        }
      },
      "source": [
        "# and now let's train the model with the data that we created\n",
        "\n",
        "for epoch in range(1000):\n",
        "    # Forward\n",
        "    y_pred = model(X)\n",
        "    \n",
        "    # Compute and print loss\n",
        "    loss = criterion(y_pred, y)\n",
        "    print('epoch: ', epoch,' loss: ', loss.item())\n",
        "    \n",
        "    # Zero the gradients\n",
        "    optimizer.zero_grad()\n",
        "    \n",
        "    # perform a backward pass (backpropagation)\n",
        "    loss.backward()\n",
        "    \n",
        "    # Update the parameters\n",
        "    optimizer.step()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch:  0  loss:  0.3161907494068146\n",
            "epoch:  1  loss:  0.3156657814979553\n",
            "epoch:  2  loss:  0.31514260172843933\n",
            "epoch:  3  loss:  0.3146211802959442\n",
            "epoch:  4  loss:  0.31410154700279236\n",
            "epoch:  5  loss:  0.3135836720466614\n",
            "epoch:  6  loss:  0.31306761503219604\n",
            "epoch:  7  loss:  0.312553346157074\n",
            "epoch:  8  loss:  0.31204086542129517\n",
            "epoch:  9  loss:  0.311530202627182\n",
            "epoch:  10  loss:  0.3110213279724121\n",
            "epoch:  11  loss:  0.31051427125930786\n",
            "epoch:  12  loss:  0.31000903248786926\n",
            "epoch:  13  loss:  0.3095055818557739\n",
            "epoch:  14  loss:  0.309004008769989\n",
            "epoch:  15  loss:  0.30850422382354736\n",
            "epoch:  16  loss:  0.30800628662109375\n",
            "epoch:  17  loss:  0.3075101673603058\n",
            "epoch:  18  loss:  0.30701586604118347\n",
            "epoch:  19  loss:  0.3065234124660492\n",
            "epoch:  20  loss:  0.30603280663490295\n",
            "epoch:  21  loss:  0.30554401874542236\n",
            "epoch:  22  loss:  0.3050571084022522\n",
            "epoch:  23  loss:  0.3045720160007477\n",
            "epoch:  24  loss:  0.3040888011455536\n",
            "epoch:  25  loss:  0.30360740423202515\n",
            "epoch:  26  loss:  0.30312788486480713\n",
            "epoch:  27  loss:  0.30265018343925476\n",
            "epoch:  28  loss:  0.3021743595600128\n",
            "epoch:  29  loss:  0.3017004132270813\n",
            "epoch:  30  loss:  0.3012283146381378\n",
            "epoch:  31  loss:  0.30075803399086\n",
            "epoch:  32  loss:  0.30028966069221497\n",
            "epoch:  33  loss:  0.299823135137558\n",
            "epoch:  34  loss:  0.29935845732688904\n",
            "epoch:  35  loss:  0.2988956570625305\n",
            "epoch:  36  loss:  0.2984347343444824\n",
            "epoch:  37  loss:  0.29797565937042236\n",
            "epoch:  38  loss:  0.29751846194267273\n",
            "epoch:  39  loss:  0.29706308245658875\n",
            "epoch:  40  loss:  0.29660964012145996\n",
            "epoch:  41  loss:  0.2961580157279968\n",
            "epoch:  42  loss:  0.2957082688808441\n",
            "epoch:  43  loss:  0.29526036977767944\n",
            "epoch:  44  loss:  0.2948143482208252\n",
            "epoch:  45  loss:  0.29437020421028137\n",
            "epoch:  46  loss:  0.293927937746048\n",
            "epoch:  47  loss:  0.2934874892234802\n",
            "epoch:  48  loss:  0.2930489182472229\n",
            "epoch:  49  loss:  0.292612224817276\n",
            "epoch:  50  loss:  0.29217737913131714\n",
            "epoch:  51  loss:  0.2917444109916687\n",
            "epoch:  52  loss:  0.2913132905960083\n",
            "epoch:  53  loss:  0.29088401794433594\n",
            "epoch:  54  loss:  0.290456622838974\n",
            "epoch:  55  loss:  0.2900310754776001\n",
            "epoch:  56  loss:  0.28960737586021423\n",
            "epoch:  57  loss:  0.2891855239868164\n",
            "epoch:  58  loss:  0.2887655198574066\n",
            "epoch:  59  loss:  0.28834739327430725\n",
            "epoch:  60  loss:  0.28793108463287354\n",
            "epoch:  61  loss:  0.28751662373542786\n",
            "epoch:  62  loss:  0.2871040105819702\n",
            "epoch:  63  loss:  0.2866932451725006\n",
            "epoch:  64  loss:  0.28628429770469666\n",
            "epoch:  65  loss:  0.28587719798088074\n",
            "epoch:  66  loss:  0.28547194600105286\n",
            "epoch:  67  loss:  0.285068541765213\n",
            "epoch:  68  loss:  0.28466692566871643\n",
            "epoch:  69  loss:  0.2842671573162079\n",
            "epoch:  70  loss:  0.2838691771030426\n",
            "epoch:  71  loss:  0.28347307443618774\n",
            "epoch:  72  loss:  0.28307873010635376\n",
            "epoch:  73  loss:  0.2826862335205078\n",
            "epoch:  74  loss:  0.2822955250740051\n",
            "epoch:  75  loss:  0.2819066643714905\n",
            "epoch:  76  loss:  0.2815195918083191\n",
            "epoch:  77  loss:  0.28113430738449097\n",
            "epoch:  78  loss:  0.2807508111000061\n",
            "epoch:  79  loss:  0.2803691327571869\n",
            "epoch:  80  loss:  0.2799892723560333\n",
            "epoch:  81  loss:  0.27961114048957825\n",
            "epoch:  82  loss:  0.2792348265647888\n",
            "epoch:  83  loss:  0.27886030077934265\n",
            "epoch:  84  loss:  0.27848753333091736\n",
            "epoch:  85  loss:  0.2781165540218353\n",
            "epoch:  86  loss:  0.27774733304977417\n",
            "epoch:  87  loss:  0.2773798704147339\n",
            "epoch:  88  loss:  0.27701419591903687\n",
            "epoch:  89  loss:  0.27665024995803833\n",
            "epoch:  90  loss:  0.27628806233406067\n",
            "epoch:  91  loss:  0.2759276330471039\n",
            "epoch:  92  loss:  0.27556896209716797\n",
            "epoch:  93  loss:  0.27521198987960815\n",
            "epoch:  94  loss:  0.2748568058013916\n",
            "epoch:  95  loss:  0.27450332045555115\n",
            "epoch:  96  loss:  0.2741515636444092\n",
            "epoch:  97  loss:  0.2738015055656433\n",
            "epoch:  98  loss:  0.2734532356262207\n",
            "epoch:  99  loss:  0.2731066048145294\n",
            "epoch:  100  loss:  0.2727617025375366\n",
            "epoch:  101  loss:  0.2724185287952423\n",
            "epoch:  102  loss:  0.2720770537853241\n",
            "epoch:  103  loss:  0.2717372477054596\n",
            "epoch:  104  loss:  0.2713991403579712\n",
            "epoch:  105  loss:  0.2710627317428589\n",
            "epoch:  106  loss:  0.2707279920578003\n",
            "epoch:  107  loss:  0.2703949213027954\n",
            "epoch:  108  loss:  0.27006351947784424\n",
            "epoch:  109  loss:  0.2697337865829468\n",
            "epoch:  110  loss:  0.269405722618103\n",
            "epoch:  111  loss:  0.2690792977809906\n",
            "epoch:  112  loss:  0.2687545120716095\n",
            "epoch:  113  loss:  0.2684313952922821\n",
            "epoch:  114  loss:  0.26810991764068604\n",
            "epoch:  115  loss:  0.2677900493144989\n",
            "epoch:  116  loss:  0.2674718499183655\n",
            "epoch:  117  loss:  0.2671552300453186\n",
            "epoch:  118  loss:  0.26684021949768066\n",
            "epoch:  119  loss:  0.26652687788009644\n",
            "epoch:  120  loss:  0.26621508598327637\n",
            "epoch:  121  loss:  0.2659049332141876\n",
            "epoch:  122  loss:  0.26559633016586304\n",
            "epoch:  123  loss:  0.2652893364429474\n",
            "epoch:  124  loss:  0.2649839520454407\n",
            "epoch:  125  loss:  0.2646801173686981\n",
            "epoch:  126  loss:  0.2643778622150421\n",
            "epoch:  127  loss:  0.26407718658447266\n",
            "epoch:  128  loss:  0.26377806067466736\n",
            "epoch:  129  loss:  0.26348045468330383\n",
            "epoch:  130  loss:  0.26318445801734924\n",
            "epoch:  131  loss:  0.2628899812698364\n",
            "epoch:  132  loss:  0.2625970244407654\n",
            "epoch:  133  loss:  0.2623056471347809\n",
            "epoch:  134  loss:  0.26201575994491577\n",
            "epoch:  135  loss:  0.26172739267349243\n",
            "epoch:  136  loss:  0.26144054532051086\n",
            "epoch:  137  loss:  0.26115521788597107\n",
            "epoch:  138  loss:  0.26087141036987305\n",
            "epoch:  139  loss:  0.260589063167572\n",
            "epoch:  140  loss:  0.2603082060813904\n",
            "epoch:  141  loss:  0.2600288689136505\n",
            "epoch:  142  loss:  0.25975096225738525\n",
            "epoch:  143  loss:  0.25947457551956177\n",
            "epoch:  144  loss:  0.2591996192932129\n",
            "epoch:  145  loss:  0.2589261829853058\n",
            "epoch:  146  loss:  0.2586541473865509\n",
            "epoch:  147  loss:  0.258383572101593\n",
            "epoch:  148  loss:  0.25811445713043213\n",
            "epoch:  149  loss:  0.25784677267074585\n",
            "epoch:  150  loss:  0.2575804889202118\n",
            "epoch:  151  loss:  0.25731566548347473\n",
            "epoch:  152  loss:  0.2570522725582123\n",
            "epoch:  153  loss:  0.25679028034210205\n",
            "epoch:  154  loss:  0.25652968883514404\n",
            "epoch:  155  loss:  0.25627046823501587\n",
            "epoch:  156  loss:  0.2560126781463623\n",
            "epoch:  157  loss:  0.25575628876686096\n",
            "epoch:  158  loss:  0.25550127029418945\n",
            "epoch:  159  loss:  0.2552476227283478\n",
            "epoch:  160  loss:  0.25499534606933594\n",
            "epoch:  161  loss:  0.25474444031715393\n",
            "epoch:  162  loss:  0.25449487566947937\n",
            "epoch:  163  loss:  0.25424668192863464\n",
            "epoch:  164  loss:  0.25399982929229736\n",
            "epoch:  165  loss:  0.25375431776046753\n",
            "epoch:  166  loss:  0.25351014733314514\n",
            "epoch:  167  loss:  0.2532672882080078\n",
            "epoch:  168  loss:  0.2530257999897003\n",
            "epoch:  169  loss:  0.2527855932712555\n",
            "epoch:  170  loss:  0.2525466978549957\n",
            "epoch:  171  loss:  0.25230908393859863\n",
            "epoch:  172  loss:  0.252072811126709\n",
            "epoch:  173  loss:  0.2518377900123596\n",
            "epoch:  174  loss:  0.2516041100025177\n",
            "epoch:  175  loss:  0.2513716220855713\n",
            "epoch:  176  loss:  0.2511404752731323\n",
            "epoch:  177  loss:  0.25091058015823364\n",
            "epoch:  178  loss:  0.25068196654319763\n",
            "epoch:  179  loss:  0.2504545748233795\n",
            "epoch:  180  loss:  0.2502284646034241\n",
            "epoch:  181  loss:  0.2500035762786865\n",
            "epoch:  182  loss:  0.24977990984916687\n",
            "epoch:  183  loss:  0.2495575100183487\n",
            "epoch:  184  loss:  0.24933631718158722\n",
            "epoch:  185  loss:  0.24911634624004364\n",
            "epoch:  186  loss:  0.24889759719371796\n",
            "epoch:  187  loss:  0.24868005514144897\n",
            "epoch:  188  loss:  0.2484637200832367\n",
            "epoch:  189  loss:  0.24824856221675873\n",
            "epoch:  190  loss:  0.24803461134433746\n",
            "epoch:  191  loss:  0.2478218525648117\n",
            "epoch:  192  loss:  0.24761024117469788\n",
            "epoch:  193  loss:  0.24739983677864075\n",
            "epoch:  194  loss:  0.24719057977199554\n",
            "epoch:  195  loss:  0.24698249995708466\n",
            "epoch:  196  loss:  0.2467755824327469\n",
            "epoch:  197  loss:  0.24656976759433746\n",
            "epoch:  198  loss:  0.24636512994766235\n",
            "epoch:  199  loss:  0.24616160988807678\n",
            "epoch:  200  loss:  0.24595923721790314\n",
            "epoch:  201  loss:  0.24575799703598022\n",
            "epoch:  202  loss:  0.24555785953998566\n",
            "epoch:  203  loss:  0.24535886943340302\n",
            "epoch:  204  loss:  0.24516095221042633\n",
            "epoch:  205  loss:  0.24496415257453918\n",
            "epoch:  206  loss:  0.2447684407234192\n",
            "epoch:  207  loss:  0.24457384645938873\n",
            "epoch:  208  loss:  0.24438032507896423\n",
            "epoch:  209  loss:  0.2441878467798233\n",
            "epoch:  210  loss:  0.24399647116661072\n",
            "epoch:  211  loss:  0.24380618333816528\n",
            "epoch:  212  loss:  0.2436169534921646\n",
            "epoch:  213  loss:  0.2434287667274475\n",
            "epoch:  214  loss:  0.24324163794517517\n",
            "epoch:  215  loss:  0.2430555671453476\n",
            "epoch:  216  loss:  0.2428705096244812\n",
            "epoch:  217  loss:  0.24268651008605957\n",
            "epoch:  218  loss:  0.2425035536289215\n",
            "epoch:  219  loss:  0.24232159554958344\n",
            "epoch:  220  loss:  0.24214065074920654\n",
            "epoch:  221  loss:  0.24196074903011322\n",
            "epoch:  222  loss:  0.2417818307876587\n",
            "epoch:  223  loss:  0.24160392582416534\n",
            "epoch:  224  loss:  0.24142703413963318\n",
            "epoch:  225  loss:  0.2412511110305786\n",
            "epoch:  226  loss:  0.24107618629932404\n",
            "epoch:  227  loss:  0.24090224504470825\n",
            "epoch:  228  loss:  0.24072927236557007\n",
            "epoch:  229  loss:  0.24055726826190948\n",
            "epoch:  230  loss:  0.2403862327337265\n",
            "epoch:  231  loss:  0.24021615087985992\n",
            "epoch:  232  loss:  0.24004705250263214\n",
            "epoch:  233  loss:  0.23987886309623718\n",
            "epoch:  234  loss:  0.23971165716648102\n",
            "epoch:  235  loss:  0.23954536020755768\n",
            "epoch:  236  loss:  0.23938001692295074\n",
            "epoch:  237  loss:  0.23921558260917664\n",
            "epoch:  238  loss:  0.23905208706855774\n",
            "epoch:  239  loss:  0.23888950049877167\n",
            "epoch:  240  loss:  0.23872782289981842\n",
            "epoch:  241  loss:  0.23856708407402039\n",
            "epoch:  242  loss:  0.23840723931789398\n",
            "epoch:  243  loss:  0.23824827373027802\n",
            "epoch:  244  loss:  0.23809021711349487\n",
            "epoch:  245  loss:  0.23793303966522217\n",
            "epoch:  246  loss:  0.2377767562866211\n",
            "epoch:  247  loss:  0.23762133717536926\n",
            "epoch:  248  loss:  0.23746681213378906\n",
            "epoch:  249  loss:  0.2373131364583969\n",
            "epoch:  250  loss:  0.2371603399515152\n",
            "epoch:  251  loss:  0.23700839281082153\n",
            "epoch:  252  loss:  0.2368573099374771\n",
            "epoch:  253  loss:  0.23670706152915955\n",
            "epoch:  254  loss:  0.23655766248703003\n",
            "epoch:  255  loss:  0.23640911281108856\n",
            "epoch:  256  loss:  0.23626138269901276\n",
            "epoch:  257  loss:  0.236114501953125\n",
            "epoch:  258  loss:  0.2359684258699417\n",
            "epoch:  259  loss:  0.23582318425178528\n",
            "epoch:  260  loss:  0.2356787621974945\n",
            "epoch:  261  loss:  0.2355351448059082\n",
            "epoch:  262  loss:  0.23539233207702637\n",
            "epoch:  263  loss:  0.2352503389120102\n",
            "epoch:  264  loss:  0.2351091355085373\n",
            "epoch:  265  loss:  0.23496869206428528\n",
            "epoch:  266  loss:  0.23482908308506012\n",
            "epoch:  267  loss:  0.23469024896621704\n",
            "epoch:  268  loss:  0.23455217480659485\n",
            "epoch:  269  loss:  0.23441490530967712\n",
            "epoch:  270  loss:  0.2342783659696579\n",
            "epoch:  271  loss:  0.23414263129234314\n",
            "epoch:  272  loss:  0.23400764167308807\n",
            "epoch:  273  loss:  0.2338734120130539\n",
            "epoch:  274  loss:  0.2337399423122406\n",
            "epoch:  275  loss:  0.233607217669487\n",
            "epoch:  276  loss:  0.2334752231836319\n",
            "epoch:  277  loss:  0.2333439737558365\n",
            "epoch:  278  loss:  0.23321346938610077\n",
            "epoch:  279  loss:  0.23308371007442474\n",
            "epoch:  280  loss:  0.23295466601848602\n",
            "epoch:  281  loss:  0.2328263223171234\n",
            "epoch:  282  loss:  0.2326987236738205\n",
            "epoch:  283  loss:  0.2325718253850937\n",
            "epoch:  284  loss:  0.2324456423521042\n",
            "epoch:  285  loss:  0.232320174574852\n",
            "epoch:  286  loss:  0.2321953922510147\n",
            "epoch:  287  loss:  0.23207132518291473\n",
            "epoch:  288  loss:  0.23194794356822968\n",
            "epoch:  289  loss:  0.23182526230812073\n",
            "epoch:  290  loss:  0.2317032516002655\n",
            "epoch:  291  loss:  0.2315819412469864\n",
            "epoch:  292  loss:  0.2314612716436386\n",
            "epoch:  293  loss:  0.23134131729602814\n",
            "epoch:  294  loss:  0.231222003698349\n",
            "epoch:  295  loss:  0.23110337555408478\n",
            "epoch:  296  loss:  0.23098540306091309\n",
            "epoch:  297  loss:  0.23086808621883392\n",
            "epoch:  298  loss:  0.2307514250278473\n",
            "epoch:  299  loss:  0.23063543438911438\n",
            "epoch:  300  loss:  0.2305200695991516\n",
            "epoch:  301  loss:  0.23040536046028137\n",
            "epoch:  302  loss:  0.23029126226902008\n",
            "epoch:  303  loss:  0.23017781972885132\n",
            "epoch:  304  loss:  0.23006503283977509\n",
            "epoch:  305  loss:  0.2299528270959854\n",
            "epoch:  306  loss:  0.22984127700328827\n",
            "epoch:  307  loss:  0.22973030805587769\n",
            "epoch:  308  loss:  0.22962000966072083\n",
            "epoch:  309  loss:  0.22951030731201172\n",
            "epoch:  310  loss:  0.22940120100975037\n",
            "epoch:  311  loss:  0.22929270565509796\n",
            "epoch:  312  loss:  0.2291848212480545\n",
            "epoch:  313  loss:  0.2290775179862976\n",
            "epoch:  314  loss:  0.22897082567214966\n",
            "epoch:  315  loss:  0.22886471450328827\n",
            "epoch:  316  loss:  0.22875919938087463\n",
            "epoch:  317  loss:  0.22865426540374756\n",
            "epoch:  318  loss:  0.22854991257190704\n",
            "epoch:  319  loss:  0.22844615578651428\n",
            "epoch:  320  loss:  0.2283429503440857\n",
            "epoch:  321  loss:  0.22824031114578247\n",
            "epoch:  322  loss:  0.2281382530927658\n",
            "epoch:  323  loss:  0.22803674638271332\n",
            "epoch:  324  loss:  0.2279358059167862\n",
            "epoch:  325  loss:  0.22783543169498444\n",
            "epoch:  326  loss:  0.22773559391498566\n",
            "epoch:  327  loss:  0.22763635218143463\n",
            "epoch:  328  loss:  0.2275376170873642\n",
            "epoch:  329  loss:  0.22743941843509674\n",
            "epoch:  330  loss:  0.22734178602695465\n",
            "epoch:  331  loss:  0.22724467515945435\n",
            "epoch:  332  loss:  0.2271481156349182\n",
            "epoch:  333  loss:  0.22705207765102386\n",
            "epoch:  334  loss:  0.2269565612077713\n",
            "epoch:  335  loss:  0.22686156630516052\n",
            "epoch:  336  loss:  0.22676712274551392\n",
            "epoch:  337  loss:  0.2266731709241867\n",
            "epoch:  338  loss:  0.22657974064350128\n",
            "epoch:  339  loss:  0.22648680210113525\n",
            "epoch:  340  loss:  0.2263944149017334\n",
            "epoch:  341  loss:  0.22630250453948975\n",
            "epoch:  342  loss:  0.22621110081672668\n",
            "epoch:  343  loss:  0.2261202186346054\n",
            "epoch:  344  loss:  0.22602981328964233\n",
            "epoch:  345  loss:  0.22593989968299866\n",
            "epoch:  346  loss:  0.22585049271583557\n",
            "epoch:  347  loss:  0.22576157748699188\n",
            "epoch:  348  loss:  0.2256731390953064\n",
            "epoch:  349  loss:  0.22558516263961792\n",
            "epoch:  350  loss:  0.22549769282341003\n",
            "epoch:  351  loss:  0.22541068494319916\n",
            "epoch:  352  loss:  0.22532416880130768\n",
            "epoch:  353  loss:  0.22523809969425201\n",
            "epoch:  354  loss:  0.22515252232551575\n",
            "epoch:  355  loss:  0.2250673919916153\n",
            "epoch:  356  loss:  0.22498273849487305\n",
            "epoch:  357  loss:  0.2248985469341278\n",
            "epoch:  358  loss:  0.22481480240821838\n",
            "epoch:  359  loss:  0.22473150491714478\n",
            "epoch:  360  loss:  0.22464866936206818\n",
            "epoch:  361  loss:  0.2245662808418274\n",
            "epoch:  362  loss:  0.22448432445526123\n",
            "epoch:  363  loss:  0.22440283000469208\n",
            "epoch:  364  loss:  0.22432176768779755\n",
            "epoch:  365  loss:  0.22424116730690002\n",
            "epoch:  366  loss:  0.22416096925735474\n",
            "epoch:  367  loss:  0.22408121824264526\n",
            "epoch:  368  loss:  0.2240018993616104\n",
            "epoch:  369  loss:  0.22392302751541138\n",
            "epoch:  370  loss:  0.2238445281982422\n",
            "epoch:  371  loss:  0.22376649081707\n",
            "epoch:  372  loss:  0.22368888556957245\n",
            "epoch:  373  loss:  0.22361166775226593\n",
            "epoch:  374  loss:  0.22353488206863403\n",
            "epoch:  375  loss:  0.22345849871635437\n",
            "epoch:  376  loss:  0.22338254749774933\n",
            "epoch:  377  loss:  0.22330696880817413\n",
            "epoch:  378  loss:  0.22323180735111237\n",
            "epoch:  379  loss:  0.22315704822540283\n",
            "epoch:  380  loss:  0.22308270633220673\n",
            "epoch:  381  loss:  0.22300875186920166\n",
            "epoch:  382  loss:  0.22293518483638763\n",
            "epoch:  383  loss:  0.22286202013492584\n",
            "epoch:  384  loss:  0.2227892279624939\n",
            "epoch:  385  loss:  0.22271685302257538\n",
            "epoch:  386  loss:  0.2226448506116867\n",
            "epoch:  387  loss:  0.22257322072982788\n",
            "epoch:  388  loss:  0.2225019931793213\n",
            "epoch:  389  loss:  0.22243113815784454\n",
            "epoch:  390  loss:  0.22236065566539764\n",
            "epoch:  391  loss:  0.2222905308008194\n",
            "epoch:  392  loss:  0.22222080826759338\n",
            "epoch:  393  loss:  0.22215145826339722\n",
            "epoch:  394  loss:  0.2220824658870697\n",
            "epoch:  395  loss:  0.22201383113861084\n",
            "epoch:  396  loss:  0.22194555401802063\n",
            "epoch:  397  loss:  0.22187764942646027\n",
            "epoch:  398  loss:  0.22181010246276855\n",
            "epoch:  399  loss:  0.2217429131269455\n",
            "epoch:  400  loss:  0.2216760814189911\n",
            "epoch:  401  loss:  0.22160960733890533\n",
            "epoch:  402  loss:  0.22154346108436584\n",
            "epoch:  403  loss:  0.2214776873588562\n",
            "epoch:  404  loss:  0.22141225636005402\n",
            "epoch:  405  loss:  0.2213471531867981\n",
            "epoch:  406  loss:  0.22128240764141083\n",
            "epoch:  407  loss:  0.22121800482273102\n",
            "epoch:  408  loss:  0.22115394473075867\n",
            "epoch:  409  loss:  0.2210901975631714\n",
            "epoch:  410  loss:  0.22102677822113037\n",
            "epoch:  411  loss:  0.220963716506958\n",
            "epoch:  412  loss:  0.22090096771717072\n",
            "epoch:  413  loss:  0.22083856165409088\n",
            "epoch:  414  loss:  0.2207764834165573\n",
            "epoch:  415  loss:  0.2207147181034088\n",
            "epoch:  416  loss:  0.22065328061580658\n",
            "epoch:  417  loss:  0.22059215605258942\n",
            "epoch:  418  loss:  0.2205313742160797\n",
            "epoch:  419  loss:  0.22047089040279388\n",
            "epoch:  420  loss:  0.22041071951389313\n",
            "epoch:  421  loss:  0.22035084664821625\n",
            "epoch:  422  loss:  0.22029130160808563\n",
            "epoch:  423  loss:  0.22023208439350128\n",
            "epoch:  424  loss:  0.22017313539981842\n",
            "epoch:  425  loss:  0.22011451423168182\n",
            "epoch:  426  loss:  0.2200561910867691\n",
            "epoch:  427  loss:  0.21999818086624146\n",
            "epoch:  428  loss:  0.21994046866893768\n",
            "epoch:  429  loss:  0.2198830246925354\n",
            "epoch:  430  loss:  0.21982590854167938\n",
            "epoch:  431  loss:  0.21976907551288605\n",
            "epoch:  432  loss:  0.2197125405073166\n",
            "epoch:  433  loss:  0.21965628862380981\n",
            "epoch:  434  loss:  0.21960031986236572\n",
            "epoch:  435  loss:  0.2195446491241455\n",
            "epoch:  436  loss:  0.21948929131031036\n",
            "epoch:  437  loss:  0.21943417191505432\n",
            "epoch:  438  loss:  0.21937935054302216\n",
            "epoch:  439  loss:  0.21932482719421387\n",
            "epoch:  440  loss:  0.21927055716514587\n",
            "epoch:  441  loss:  0.21921658515930176\n",
            "epoch:  442  loss:  0.21916288137435913\n",
            "epoch:  443  loss:  0.2191094309091568\n",
            "epoch:  444  loss:  0.21905627846717834\n",
            "epoch:  445  loss:  0.21900339424610138\n",
            "epoch:  446  loss:  0.2189507633447647\n",
            "epoch:  447  loss:  0.21889843046665192\n",
            "epoch:  448  loss:  0.21884633600711823\n",
            "epoch:  449  loss:  0.21879450976848602\n",
            "epoch:  450  loss:  0.21874293684959412\n",
            "epoch:  451  loss:  0.2186916470527649\n",
            "epoch:  452  loss:  0.21864062547683716\n",
            "epoch:  453  loss:  0.21858982741832733\n",
            "epoch:  454  loss:  0.2185393124818802\n",
            "epoch:  455  loss:  0.21848905086517334\n",
            "epoch:  456  loss:  0.2184390276670456\n",
            "epoch:  457  loss:  0.21838927268981934\n",
            "epoch:  458  loss:  0.21833975613117218\n",
            "epoch:  459  loss:  0.21829049289226532\n",
            "epoch:  460  loss:  0.21824148297309875\n",
            "epoch:  461  loss:  0.2181927114725113\n",
            "epoch:  462  loss:  0.21814417839050293\n",
            "epoch:  463  loss:  0.21809589862823486\n",
            "epoch:  464  loss:  0.2180478721857071\n",
            "epoch:  465  loss:  0.21800008416175842\n",
            "epoch:  466  loss:  0.21795251965522766\n",
            "epoch:  467  loss:  0.2179051786661148\n",
            "epoch:  468  loss:  0.21785810589790344\n",
            "epoch:  469  loss:  0.2178112417459488\n",
            "epoch:  470  loss:  0.21776463091373444\n",
            "epoch:  471  loss:  0.217718243598938\n",
            "epoch:  472  loss:  0.21767207980155945\n",
            "epoch:  473  loss:  0.21762615442276\n",
            "epoch:  474  loss:  0.21758045256137848\n",
            "epoch:  475  loss:  0.21753498911857605\n",
            "epoch:  476  loss:  0.21748973429203033\n",
            "epoch:  477  loss:  0.21744471788406372\n",
            "epoch:  478  loss:  0.21739992499351501\n",
            "epoch:  479  loss:  0.21735532581806183\n",
            "epoch:  480  loss:  0.21731096506118774\n",
            "epoch:  481  loss:  0.21726684272289276\n",
            "epoch:  482  loss:  0.2172229140996933\n",
            "epoch:  483  loss:  0.21717919409275055\n",
            "epoch:  484  loss:  0.21713568270206451\n",
            "epoch:  485  loss:  0.21709240972995758\n",
            "epoch:  486  loss:  0.21704934537410736\n",
            "epoch:  487  loss:  0.21700648963451385\n",
            "epoch:  488  loss:  0.21696384251117706\n",
            "epoch:  489  loss:  0.21692140400409698\n",
            "epoch:  490  loss:  0.21687917411327362\n",
            "epoch:  491  loss:  0.21683715283870697\n",
            "epoch:  492  loss:  0.21679532527923584\n",
            "epoch:  493  loss:  0.21675372123718262\n",
            "epoch:  494  loss:  0.21671231091022491\n",
            "epoch:  495  loss:  0.21667109429836273\n",
            "epoch:  496  loss:  0.21663005650043488\n",
            "epoch:  497  loss:  0.21658925712108612\n",
            "epoch:  498  loss:  0.21654865145683289\n",
            "epoch:  499  loss:  0.21650822460651398\n",
            "epoch:  500  loss:  0.2164679914712906\n",
            "epoch:  501  loss:  0.2164279669523239\n",
            "epoch:  502  loss:  0.21638812124729156\n",
            "epoch:  503  loss:  0.21634846925735474\n",
            "epoch:  504  loss:  0.21630902588367462\n",
            "epoch:  505  loss:  0.21626976132392883\n",
            "epoch:  506  loss:  0.21623067557811737\n",
            "epoch:  507  loss:  0.21619178354740143\n",
            "epoch:  508  loss:  0.2161531001329422\n",
            "epoch:  509  loss:  0.2161145955324173\n",
            "epoch:  510  loss:  0.21607623994350433\n",
            "epoch:  511  loss:  0.2160380780696869\n",
            "epoch:  512  loss:  0.21600013971328735\n",
            "epoch:  513  loss:  0.21596235036849976\n",
            "epoch:  514  loss:  0.21592473983764648\n",
            "epoch:  515  loss:  0.21588732302188873\n",
            "epoch:  516  loss:  0.21585005521774292\n",
            "epoch:  517  loss:  0.21581299602985382\n",
            "epoch:  518  loss:  0.21577608585357666\n",
            "epoch:  519  loss:  0.2157393842935562\n",
            "epoch:  520  loss:  0.2157028317451477\n",
            "epoch:  521  loss:  0.21566644310951233\n",
            "epoch:  522  loss:  0.21563024818897247\n",
            "epoch:  523  loss:  0.21559420228004456\n",
            "epoch:  524  loss:  0.21555835008621216\n",
            "epoch:  525  loss:  0.2155226469039917\n",
            "epoch:  526  loss:  0.21548712253570557\n",
            "epoch:  527  loss:  0.21545176208019257\n",
            "epoch:  528  loss:  0.2154165655374527\n",
            "epoch:  529  loss:  0.21538153290748596\n",
            "epoch:  530  loss:  0.21534667909145355\n",
            "epoch:  531  loss:  0.21531198918819427\n",
            "epoch:  532  loss:  0.21527743339538574\n",
            "epoch:  533  loss:  0.21524305641651154\n",
            "epoch:  534  loss:  0.21520884335041046\n",
            "epoch:  535  loss:  0.21517477929592133\n",
            "epoch:  536  loss:  0.21514087915420532\n",
            "epoch:  537  loss:  0.21510712802410126\n",
            "epoch:  538  loss:  0.21507354080677032\n",
            "epoch:  539  loss:  0.21504013240337372\n",
            "epoch:  540  loss:  0.21500684320926666\n",
            "epoch:  541  loss:  0.21497371792793274\n",
            "epoch:  542  loss:  0.21494075655937195\n",
            "epoch:  543  loss:  0.2149079293012619\n",
            "epoch:  544  loss:  0.214875265955925\n",
            "epoch:  545  loss:  0.2148427516222\n",
            "epoch:  546  loss:  0.21481038630008698\n",
            "epoch:  547  loss:  0.21477816998958588\n",
            "epoch:  548  loss:  0.21474610269069672\n",
            "epoch:  549  loss:  0.2147141695022583\n",
            "epoch:  550  loss:  0.21468240022659302\n",
            "epoch:  551  loss:  0.21465077996253967\n",
            "epoch:  552  loss:  0.21461927890777588\n",
            "epoch:  553  loss:  0.21458791196346283\n",
            "epoch:  554  loss:  0.2145567238330841\n",
            "epoch:  555  loss:  0.21452565491199493\n",
            "epoch:  556  loss:  0.2144947499036789\n",
            "epoch:  557  loss:  0.2144639641046524\n",
            "epoch:  558  loss:  0.21443332731723785\n",
            "epoch:  559  loss:  0.21440283954143524\n",
            "epoch:  560  loss:  0.214372456073761\n",
            "epoch:  561  loss:  0.21434223651885986\n",
            "epoch:  562  loss:  0.21431216597557068\n",
            "epoch:  563  loss:  0.21428219974040985\n",
            "epoch:  564  loss:  0.21425236761569977\n",
            "epoch:  565  loss:  0.21422269940376282\n",
            "epoch:  566  loss:  0.21419313549995422\n",
            "epoch:  567  loss:  0.21416372060775757\n",
            "epoch:  568  loss:  0.21413443982601166\n",
            "epoch:  569  loss:  0.2141052782535553\n",
            "epoch:  570  loss:  0.21407625079154968\n",
            "epoch:  571  loss:  0.21404734253883362\n",
            "epoch:  572  loss:  0.2140185832977295\n",
            "epoch:  573  loss:  0.21398994326591492\n",
            "epoch:  574  loss:  0.2139614224433899\n",
            "epoch:  575  loss:  0.2139330506324768\n",
            "epoch:  576  loss:  0.21390478312969208\n",
            "epoch:  577  loss:  0.2138766497373581\n",
            "epoch:  578  loss:  0.21384863555431366\n",
            "epoch:  579  loss:  0.21382075548171997\n",
            "epoch:  580  loss:  0.21379299461841583\n",
            "epoch:  581  loss:  0.21376532316207886\n",
            "epoch:  582  loss:  0.21373781561851501\n",
            "epoch:  583  loss:  0.21371042728424072\n",
            "epoch:  584  loss:  0.2136831432580948\n",
            "epoch:  585  loss:  0.2136559784412384\n",
            "epoch:  586  loss:  0.21362893283367157\n",
            "epoch:  587  loss:  0.2136020064353943\n",
            "epoch:  588  loss:  0.21357521414756775\n",
            "epoch:  589  loss:  0.21354851126670837\n",
            "epoch:  590  loss:  0.21352194249629974\n",
            "epoch:  591  loss:  0.21349549293518066\n",
            "epoch:  592  loss:  0.21346913278102875\n",
            "epoch:  593  loss:  0.21344292163848877\n",
            "epoch:  594  loss:  0.21341679990291595\n",
            "epoch:  595  loss:  0.2133907824754715\n",
            "epoch:  596  loss:  0.21336489915847778\n",
            "epoch:  597  loss:  0.21333912014961243\n",
            "epoch:  598  loss:  0.21331346035003662\n",
            "epoch:  599  loss:  0.21328790485858917\n",
            "epoch:  600  loss:  0.2132624387741089\n",
            "epoch:  601  loss:  0.21323712170124054\n",
            "epoch:  602  loss:  0.21321187913417816\n",
            "epoch:  603  loss:  0.21318677067756653\n",
            "epoch:  604  loss:  0.21316173672676086\n",
            "epoch:  605  loss:  0.21313683688640594\n",
            "epoch:  606  loss:  0.2131120264530182\n",
            "epoch:  607  loss:  0.21308733522891998\n",
            "epoch:  608  loss:  0.21306274831295013\n",
            "epoch:  609  loss:  0.21303825080394745\n",
            "epoch:  610  loss:  0.21301385760307312\n",
            "epoch:  611  loss:  0.21298959851264954\n",
            "epoch:  612  loss:  0.21296541392803192\n",
            "epoch:  613  loss:  0.21294133365154266\n",
            "epoch:  614  loss:  0.21291737258434296\n",
            "epoch:  615  loss:  0.2128935009241104\n",
            "epoch:  616  loss:  0.21286971867084503\n",
            "epoch:  617  loss:  0.212846040725708\n",
            "epoch:  618  loss:  0.21282246708869934\n",
            "epoch:  619  loss:  0.21279899775981903\n",
            "epoch:  620  loss:  0.2127756029367447\n",
            "epoch:  621  loss:  0.2127523422241211\n",
            "epoch:  622  loss:  0.21272915601730347\n",
            "epoch:  623  loss:  0.2127060741186142\n",
            "epoch:  624  loss:  0.2126830667257309\n",
            "epoch:  625  loss:  0.21266019344329834\n",
            "epoch:  626  loss:  0.21263737976551056\n",
            "epoch:  627  loss:  0.21261468529701233\n",
            "epoch:  628  loss:  0.21259205043315887\n",
            "epoch:  629  loss:  0.21256954967975616\n",
            "epoch:  630  loss:  0.21254710853099823\n",
            "epoch:  631  loss:  0.21252478659152985\n",
            "epoch:  632  loss:  0.21250253915786743\n",
            "epoch:  633  loss:  0.21248038113117218\n",
            "epoch:  634  loss:  0.21245832741260529\n",
            "epoch:  635  loss:  0.21243636310100555\n",
            "epoch:  636  loss:  0.21241448819637299\n",
            "epoch:  637  loss:  0.2123926877975464\n",
            "epoch:  638  loss:  0.21237099170684814\n",
            "epoch:  639  loss:  0.21234935522079468\n",
            "epoch:  640  loss:  0.21232785284519196\n",
            "epoch:  641  loss:  0.21230639517307281\n",
            "epoch:  642  loss:  0.21228504180908203\n",
            "epoch:  643  loss:  0.21226376295089722\n",
            "epoch:  644  loss:  0.21224258840084076\n",
            "epoch:  645  loss:  0.21222150325775146\n",
            "epoch:  646  loss:  0.21220049262046814\n",
            "epoch:  647  loss:  0.21217955648899078\n",
            "epoch:  648  loss:  0.21215872466564178\n",
            "epoch:  649  loss:  0.21213796734809875\n",
            "epoch:  650  loss:  0.2121172845363617\n",
            "epoch:  651  loss:  0.2120966911315918\n",
            "epoch:  652  loss:  0.21207617223262787\n",
            "epoch:  653  loss:  0.2120557427406311\n",
            "epoch:  654  loss:  0.2120353877544403\n",
            "epoch:  655  loss:  0.21201512217521667\n",
            "epoch:  656  loss:  0.2119949460029602\n",
            "epoch:  657  loss:  0.2119748294353485\n",
            "epoch:  658  loss:  0.21195480227470398\n",
            "epoch:  659  loss:  0.21193484961986542\n",
            "epoch:  660  loss:  0.21191498637199402\n",
            "epoch:  661  loss:  0.2118951827287674\n",
            "epoch:  662  loss:  0.21187548339366913\n",
            "epoch:  663  loss:  0.21185582876205444\n",
            "epoch:  664  loss:  0.21183627843856812\n",
            "epoch:  665  loss:  0.21181677281856537\n",
            "epoch:  666  loss:  0.21179737150669098\n",
            "epoch:  667  loss:  0.21177804470062256\n",
            "epoch:  668  loss:  0.2117587774991989\n",
            "epoch:  669  loss:  0.21173958480358124\n",
            "epoch:  670  loss:  0.21172048151493073\n",
            "epoch:  671  loss:  0.211701437830925\n",
            "epoch:  672  loss:  0.2116824984550476\n",
            "epoch:  673  loss:  0.2116636037826538\n",
            "epoch:  674  loss:  0.21164476871490479\n",
            "epoch:  675  loss:  0.21162603795528412\n",
            "epoch:  676  loss:  0.21160736680030823\n",
            "epoch:  677  loss:  0.2115887552499771\n",
            "epoch:  678  loss:  0.21157021820545197\n",
            "epoch:  679  loss:  0.2115517556667328\n",
            "epoch:  680  loss:  0.21153338253498077\n",
            "epoch:  681  loss:  0.21151505410671234\n",
            "epoch:  682  loss:  0.21149681508541107\n",
            "epoch:  683  loss:  0.21147862076759338\n",
            "epoch:  684  loss:  0.21146051585674286\n",
            "epoch:  685  loss:  0.2114424705505371\n",
            "epoch:  686  loss:  0.21142449975013733\n",
            "epoch:  687  loss:  0.21140657365322113\n",
            "epoch:  688  loss:  0.21138876676559448\n",
            "epoch:  689  loss:  0.21137098968029022\n",
            "epoch:  690  loss:  0.21135325729846954\n",
            "epoch:  691  loss:  0.21133564412593842\n",
            "epoch:  692  loss:  0.21131804585456848\n",
            "epoch:  693  loss:  0.2113005369901657\n",
            "epoch:  694  loss:  0.2112831026315689\n",
            "epoch:  695  loss:  0.2112657129764557\n",
            "epoch:  696  loss:  0.21124839782714844\n",
            "epoch:  697  loss:  0.21123114228248596\n",
            "epoch:  698  loss:  0.21121396124362946\n",
            "epoch:  699  loss:  0.21119683980941772\n",
            "epoch:  700  loss:  0.21117976307868958\n",
            "epoch:  701  loss:  0.2111627757549286\n",
            "epoch:  702  loss:  0.21114583313465118\n",
            "epoch:  703  loss:  0.21112896502017975\n",
            "epoch:  704  loss:  0.2111121565103531\n",
            "epoch:  705  loss:  0.21109539270401\n",
            "epoch:  706  loss:  0.2110787034034729\n",
            "epoch:  707  loss:  0.21106207370758057\n",
            "epoch:  708  loss:  0.2110455185174942\n",
            "epoch:  709  loss:  0.21102899312973022\n",
            "epoch:  710  loss:  0.2110125571489334\n",
            "epoch:  711  loss:  0.21099616587162018\n",
            "epoch:  712  loss:  0.21097984910011292\n",
            "epoch:  713  loss:  0.21096354722976685\n",
            "epoch:  714  loss:  0.21094734966754913\n",
            "epoch:  715  loss:  0.210931196808815\n",
            "epoch:  716  loss:  0.21091510355472565\n",
            "epoch:  717  loss:  0.21089905500411987\n",
            "epoch:  718  loss:  0.21088308095932007\n",
            "epoch:  719  loss:  0.21086713671684265\n",
            "epoch:  720  loss:  0.2108512669801712\n",
            "epoch:  721  loss:  0.21083547174930573\n",
            "epoch:  722  loss:  0.21081972122192383\n",
            "epoch:  723  loss:  0.2108040153980255\n",
            "epoch:  724  loss:  0.21078835427761078\n",
            "epoch:  725  loss:  0.2107727825641632\n",
            "epoch:  726  loss:  0.21075724065303802\n",
            "epoch:  727  loss:  0.21074174344539642\n",
            "epoch:  728  loss:  0.21072633564472198\n",
            "epoch:  729  loss:  0.21071094274520874\n",
            "epoch:  730  loss:  0.21069563925266266\n",
            "epoch:  731  loss:  0.21068038046360016\n",
            "epoch:  732  loss:  0.21066515147686005\n",
            "epoch:  733  loss:  0.2106499969959259\n",
            "epoch:  734  loss:  0.21063488721847534\n",
            "epoch:  735  loss:  0.21061982214450836\n",
            "epoch:  736  loss:  0.21060481667518616\n",
            "epoch:  737  loss:  0.21058987081050873\n",
            "epoch:  738  loss:  0.21057496964931488\n",
            "epoch:  739  loss:  0.21056011319160461\n",
            "epoch:  740  loss:  0.21054530143737793\n",
            "epoch:  741  loss:  0.2105305790901184\n",
            "epoch:  742  loss:  0.21051587164402008\n",
            "epoch:  743  loss:  0.21050122380256653\n",
            "epoch:  744  loss:  0.21048662066459656\n",
            "epoch:  745  loss:  0.21047207713127136\n",
            "epoch:  746  loss:  0.21045756340026855\n",
            "epoch:  747  loss:  0.21044312417507172\n",
            "epoch:  748  loss:  0.21042871475219727\n",
            "epoch:  749  loss:  0.2104143500328064\n",
            "epoch:  750  loss:  0.2104000598192215\n",
            "epoch:  751  loss:  0.21038581430912018\n",
            "epoch:  752  loss:  0.21037159860134125\n",
            "epoch:  753  loss:  0.2103574424982071\n",
            "epoch:  754  loss:  0.21034330129623413\n",
            "epoch:  755  loss:  0.21032923460006714\n",
            "epoch:  756  loss:  0.21031522750854492\n",
            "epoch:  757  loss:  0.2103012353181839\n",
            "epoch:  758  loss:  0.21028731763362885\n",
            "epoch:  759  loss:  0.21027341485023499\n",
            "epoch:  760  loss:  0.2102595865726471\n",
            "epoch:  761  loss:  0.21024580299854279\n",
            "epoch:  762  loss:  0.21023206412792206\n",
            "epoch:  763  loss:  0.21021835505962372\n",
            "epoch:  764  loss:  0.21020469069480896\n",
            "epoch:  765  loss:  0.21019107103347778\n",
            "epoch:  766  loss:  0.210177481174469\n",
            "epoch:  767  loss:  0.21016398072242737\n",
            "epoch:  768  loss:  0.21015049517154694\n",
            "epoch:  769  loss:  0.21013705432415009\n",
            "epoch:  770  loss:  0.210123673081398\n",
            "epoch:  771  loss:  0.21011030673980713\n",
            "epoch:  772  loss:  0.21009700000286102\n",
            "epoch:  773  loss:  0.2100837379693985\n",
            "epoch:  774  loss:  0.21007050573825836\n",
            "epoch:  775  loss:  0.210057333111763\n",
            "epoch:  776  loss:  0.21004419028759003\n",
            "epoch:  777  loss:  0.21003109216690063\n",
            "epoch:  778  loss:  0.21001805365085602\n",
            "epoch:  779  loss:  0.2100050151348114\n",
            "epoch:  780  loss:  0.20999203622341156\n",
            "epoch:  781  loss:  0.2099791169166565\n",
            "epoch:  782  loss:  0.20996622741222382\n",
            "epoch:  783  loss:  0.20995336771011353\n",
            "epoch:  784  loss:  0.209940567612648\n",
            "epoch:  785  loss:  0.2099277824163437\n",
            "epoch:  786  loss:  0.20991505682468414\n",
            "epoch:  787  loss:  0.2099023461341858\n",
            "epoch:  788  loss:  0.20988969504833221\n",
            "epoch:  789  loss:  0.20987708866596222\n",
            "epoch:  790  loss:  0.2098645120859146\n",
            "epoch:  791  loss:  0.2098519653081894\n",
            "epoch:  792  loss:  0.20983947813510895\n",
            "epoch:  793  loss:  0.2098270207643509\n",
            "epoch:  794  loss:  0.20981459319591522\n",
            "epoch:  795  loss:  0.20980221033096313\n",
            "epoch:  796  loss:  0.20978987216949463\n",
            "epoch:  797  loss:  0.20977754890918732\n",
            "epoch:  798  loss:  0.20976528525352478\n",
            "epoch:  799  loss:  0.20975305140018463\n",
            "epoch:  800  loss:  0.20974084734916687\n",
            "epoch:  801  loss:  0.2097286880016327\n",
            "epoch:  802  loss:  0.2097165733575821\n",
            "epoch:  803  loss:  0.20970448851585388\n",
            "epoch:  804  loss:  0.20969241857528687\n",
            "epoch:  805  loss:  0.20968040823936462\n",
            "epoch:  806  loss:  0.20966841280460358\n",
            "epoch:  807  loss:  0.2096564918756485\n",
            "epoch:  808  loss:  0.20964458584785461\n",
            "epoch:  809  loss:  0.20963270962238312\n",
            "epoch:  810  loss:  0.209620863199234\n",
            "epoch:  811  loss:  0.20960906147956848\n",
            "epoch:  812  loss:  0.20959730446338654\n",
            "epoch:  813  loss:  0.20958556234836578\n",
            "epoch:  814  loss:  0.2095738649368286\n",
            "epoch:  815  loss:  0.20956219732761383\n",
            "epoch:  816  loss:  0.20955054461956024\n",
            "epoch:  817  loss:  0.20953896641731262\n",
            "epoch:  818  loss:  0.2095274031162262\n",
            "epoch:  819  loss:  0.20951586961746216\n",
            "epoch:  820  loss:  0.2095043659210205\n",
            "epoch:  821  loss:  0.20949290692806244\n",
            "epoch:  822  loss:  0.20948146283626556\n",
            "epoch:  823  loss:  0.20947009325027466\n",
            "epoch:  824  loss:  0.20945869386196136\n",
            "epoch:  825  loss:  0.20944736897945404\n",
            "epoch:  826  loss:  0.2094360738992691\n",
            "epoch:  827  loss:  0.20942480862140656\n",
            "epoch:  828  loss:  0.2094135731458664\n",
            "epoch:  829  loss:  0.20940233767032623\n",
            "epoch:  830  loss:  0.20939116179943085\n",
            "epoch:  831  loss:  0.20938004553318024\n",
            "epoch:  832  loss:  0.20936892926692963\n",
            "epoch:  833  loss:  0.2093578428030014\n",
            "epoch:  834  loss:  0.20934681594371796\n",
            "epoch:  835  loss:  0.20933577418327332\n",
            "epoch:  836  loss:  0.20932477712631226\n",
            "epoch:  837  loss:  0.20931382477283478\n",
            "epoch:  838  loss:  0.2093029022216797\n",
            "epoch:  839  loss:  0.20929200947284698\n",
            "epoch:  840  loss:  0.20928113162517548\n",
            "epoch:  841  loss:  0.20927029848098755\n",
            "epoch:  842  loss:  0.20925948023796082\n",
            "epoch:  843  loss:  0.20924870669841766\n",
            "epoch:  844  loss:  0.2092379629611969\n",
            "epoch:  845  loss:  0.20922723412513733\n",
            "epoch:  846  loss:  0.20921654999256134\n",
            "epoch:  847  loss:  0.20920588076114655\n",
            "epoch:  848  loss:  0.20919525623321533\n",
            "epoch:  849  loss:  0.2091846466064453\n",
            "epoch:  850  loss:  0.20917406678199768\n",
            "epoch:  851  loss:  0.20916351675987244\n",
            "epoch:  852  loss:  0.20915301144123077\n",
            "epoch:  853  loss:  0.2091425061225891\n",
            "epoch:  854  loss:  0.20913204550743103\n",
            "epoch:  855  loss:  0.20912159979343414\n",
            "epoch:  856  loss:  0.20911118388175964\n",
            "epoch:  857  loss:  0.20910081267356873\n",
            "epoch:  858  loss:  0.209090456366539\n",
            "epoch:  859  loss:  0.20908011496067047\n",
            "epoch:  860  loss:  0.20906983315944672\n",
            "epoch:  861  loss:  0.20905955135822296\n",
            "epoch:  862  loss:  0.2090492993593216\n",
            "epoch:  863  loss:  0.2090390920639038\n",
            "epoch:  864  loss:  0.20902888476848602\n",
            "epoch:  865  loss:  0.20901872217655182\n",
            "epoch:  866  loss:  0.20900858938694\n",
            "epoch:  867  loss:  0.20899847149848938\n",
            "epoch:  868  loss:  0.20898838341236115\n",
            "epoch:  869  loss:  0.2089783102273941\n",
            "epoch:  870  loss:  0.20896828174591064\n",
            "epoch:  871  loss:  0.20895826816558838\n",
            "epoch:  872  loss:  0.2089482694864273\n",
            "epoch:  873  loss:  0.20893831551074982\n",
            "epoch:  874  loss:  0.20892837643623352\n",
            "epoch:  875  loss:  0.2089184820652008\n",
            "epoch:  876  loss:  0.2089085727930069\n",
            "epoch:  877  loss:  0.20889872312545776\n",
            "epoch:  878  loss:  0.20888888835906982\n",
            "epoch:  879  loss:  0.20887906849384308\n",
            "epoch:  880  loss:  0.20886927843093872\n",
            "epoch:  881  loss:  0.20885951817035675\n",
            "epoch:  882  loss:  0.20884977281093597\n",
            "epoch:  883  loss:  0.20884007215499878\n",
            "epoch:  884  loss:  0.20883037149906158\n",
            "epoch:  885  loss:  0.20882068574428558\n",
            "epoch:  886  loss:  0.20881104469299316\n",
            "epoch:  887  loss:  0.20880143344402313\n",
            "epoch:  888  loss:  0.2087918221950531\n",
            "epoch:  889  loss:  0.20878225564956665\n",
            "epoch:  890  loss:  0.2087727040052414\n",
            "epoch:  891  loss:  0.20876316726207733\n",
            "epoch:  892  loss:  0.20875366032123566\n",
            "epoch:  893  loss:  0.20874418318271637\n",
            "epoch:  894  loss:  0.20873470604419708\n",
            "epoch:  895  loss:  0.20872527360916138\n",
            "epoch:  896  loss:  0.20871585607528687\n",
            "epoch:  897  loss:  0.20870646834373474\n",
            "epoch:  898  loss:  0.2086970955133438\n",
            "epoch:  899  loss:  0.20868775248527527\n",
            "epoch:  900  loss:  0.20867842435836792\n",
            "epoch:  901  loss:  0.20866911113262177\n",
            "epoch:  902  loss:  0.208659827709198\n",
            "epoch:  903  loss:  0.20865055918693542\n",
            "epoch:  904  loss:  0.20864132046699524\n",
            "epoch:  905  loss:  0.20863211154937744\n",
            "epoch:  906  loss:  0.20862290263175964\n",
            "epoch:  907  loss:  0.20861373841762543\n",
            "epoch:  908  loss:  0.2086045742034912\n",
            "epoch:  909  loss:  0.20859543979167938\n",
            "epoch:  910  loss:  0.20858630537986755\n",
            "epoch:  911  loss:  0.2085772156715393\n",
            "epoch:  912  loss:  0.20856815576553345\n",
            "epoch:  913  loss:  0.20855912566184998\n",
            "epoch:  914  loss:  0.2085500806570053\n",
            "epoch:  915  loss:  0.20854106545448303\n",
            "epoch:  916  loss:  0.20853208005428314\n",
            "epoch:  917  loss:  0.20852312445640564\n",
            "epoch:  918  loss:  0.20851413905620575\n",
            "epoch:  919  loss:  0.20850522816181183\n",
            "epoch:  920  loss:  0.2084963023662567\n",
            "epoch:  921  loss:  0.208487406373024\n",
            "epoch:  922  loss:  0.20847854018211365\n",
            "epoch:  923  loss:  0.2084696739912033\n",
            "epoch:  924  loss:  0.20846085250377655\n",
            "epoch:  925  loss:  0.208452045917511\n",
            "epoch:  926  loss:  0.20844323933124542\n",
            "epoch:  927  loss:  0.20843446254730225\n",
            "epoch:  928  loss:  0.20842570066452026\n",
            "epoch:  929  loss:  0.20841698348522186\n",
            "epoch:  930  loss:  0.20840825140476227\n",
            "epoch:  931  loss:  0.20839956402778625\n",
            "epoch:  932  loss:  0.20839087665081024\n",
            "epoch:  933  loss:  0.20838218927383423\n",
            "epoch:  934  loss:  0.208373561501503\n",
            "epoch:  935  loss:  0.20836493372917175\n",
            "epoch:  936  loss:  0.2083563208580017\n",
            "epoch:  937  loss:  0.20834773778915405\n",
            "epoch:  938  loss:  0.2083391547203064\n",
            "epoch:  939  loss:  0.20833061635494232\n",
            "epoch:  940  loss:  0.20832206308841705\n",
            "epoch:  941  loss:  0.20831355452537537\n",
            "epoch:  942  loss:  0.20830506086349487\n",
            "epoch:  943  loss:  0.20829656720161438\n",
            "epoch:  944  loss:  0.20828808844089508\n",
            "epoch:  945  loss:  0.20827965438365936\n",
            "epoch:  946  loss:  0.20827122032642365\n",
            "epoch:  947  loss:  0.20826280117034912\n",
            "epoch:  948  loss:  0.20825441181659698\n",
            "epoch:  949  loss:  0.20824602246284485\n",
            "epoch:  950  loss:  0.2082376629114151\n",
            "epoch:  951  loss:  0.20822931826114655\n",
            "epoch:  952  loss:  0.208220973610878\n",
            "epoch:  953  loss:  0.20821267366409302\n",
            "epoch:  954  loss:  0.20820438861846924\n",
            "epoch:  955  loss:  0.20819610357284546\n",
            "epoch:  956  loss:  0.20818783342838287\n",
            "epoch:  957  loss:  0.20817959308624268\n",
            "epoch:  958  loss:  0.20817136764526367\n",
            "epoch:  959  loss:  0.20816314220428467\n",
            "epoch:  960  loss:  0.20815493166446686\n",
            "epoch:  961  loss:  0.20814673602581024\n",
            "epoch:  962  loss:  0.2081385850906372\n",
            "epoch:  963  loss:  0.20813043415546417\n",
            "epoch:  964  loss:  0.20812231302261353\n",
            "epoch:  965  loss:  0.20811417698860168\n",
            "epoch:  966  loss:  0.20810610055923462\n",
            "epoch:  967  loss:  0.20809800922870636\n",
            "epoch:  968  loss:  0.2080899327993393\n",
            "epoch:  969  loss:  0.20808187127113342\n",
            "epoch:  970  loss:  0.20807383954524994\n",
            "epoch:  971  loss:  0.20806579291820526\n",
            "epoch:  972  loss:  0.20805777609348297\n",
            "epoch:  973  loss:  0.20804978907108307\n",
            "epoch:  974  loss:  0.20804180204868317\n",
            "epoch:  975  loss:  0.20803384482860565\n",
            "epoch:  976  loss:  0.20802590250968933\n",
            "epoch:  977  loss:  0.208017960190773\n",
            "epoch:  978  loss:  0.20801003277301788\n",
            "epoch:  979  loss:  0.20800212025642395\n",
            "epoch:  980  loss:  0.2079942226409912\n",
            "epoch:  981  loss:  0.20798635482788086\n",
            "epoch:  982  loss:  0.2079784870147705\n",
            "epoch:  983  loss:  0.20797063410282135\n",
            "epoch:  984  loss:  0.20796281099319458\n",
            "epoch:  985  loss:  0.20795497298240662\n",
            "epoch:  986  loss:  0.20794717967510223\n",
            "epoch:  987  loss:  0.20793937146663666\n",
            "epoch:  988  loss:  0.20793160796165466\n",
            "epoch:  989  loss:  0.20792384445667267\n",
            "epoch:  990  loss:  0.20791608095169067\n",
            "epoch:  991  loss:  0.20790834724903107\n",
            "epoch:  992  loss:  0.20790061354637146\n",
            "epoch:  993  loss:  0.20789290964603424\n",
            "epoch:  994  loss:  0.20788520574569702\n",
            "epoch:  995  loss:  0.207877516746521\n",
            "epoch:  996  loss:  0.20786984264850616\n",
            "epoch:  997  loss:  0.20786219835281372\n",
            "epoch:  998  loss:  0.20785453915596008\n",
            "epoch:  999  loss:  0.20784692466259003\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}