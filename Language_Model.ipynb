{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Language Model",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ronenbendavid/IDC_NLP/blob/master/Language_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_g_D5JJz8BYX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from random import sample\n",
        "import random\n",
        "from google.colab import drive\n",
        "import json"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3enPCGBF8FlX",
        "colab_type": "code",
        "outputId": "b11ef461-b6cc-4b9f-beef-a7c9cb5a9276",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "prgzgtt8Jw4Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def read_data(path):\n",
        "    lines = open(path).read().strip().split('\\n')\n",
        "    texts = []\n",
        "    for line in lines:\n",
        "      try:\n",
        "        tweet = json.loads(line)\n",
        "        texts.append(tweet['text'].lower().strip())\n",
        "      except:\n",
        "        pass\n",
        "    return texts\n",
        "data = read_data('/content/drive/My Drive/Colab Notebooks/ML course/data/data.json')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xuthGqk1vLtT",
        "colab_type": "code",
        "outputId": "f55f039f-9519-4fb4-a630-af944511f0de",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(random.choice(data))\n",
        "print(len(data))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "we took jesse ice skating today for christmas in manhattan.  we didn't intend to go for 4 hours but that's how long… https://t.co/oncfeixl3w\n",
            "3723\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6rKIB5o_vQO8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "EOS_TOKEN = 0\n",
        "MAX_SEQ_LEN = 100\n",
        "\n",
        "class Vocab:\n",
        "    def __init__(self):\n",
        "        self.char2id = {}\n",
        "        self.id2char = {}\n",
        "        self.n_chars = 1\n",
        "        \n",
        "    def index_sentence(self, sentence):\n",
        "      indexes = [self.index_char(c) for c in sentence]\n",
        "      indexes.append(EOS_TOKEN)\n",
        "      return indexes\n",
        "    \n",
        "    def index_char(self, c):\n",
        "        if c not in self.char2id:\n",
        "            self.char2id[c] = self.n_chars\n",
        "            self.id2char[self.n_chars] = c\n",
        "            self.n_chars += 1\n",
        "        return self.char2id[c]\n",
        "            \n",
        "            \n",
        "def prepare_data(data):\n",
        "    vocab = Vocab()\n",
        "    data_sequences = []\n",
        "    for sentence in data:\n",
        "        if len(sentence) <= MAX_SEQ_LEN:\n",
        "            indexes = vocab.index_sentence(sentence)\n",
        "            data_sequences.append(indexes)\n",
        "            \n",
        "    return data_sequences, vocab"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "noIY3zWKvhBd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_sequences, vocab = prepare_data(data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ke1LyUQNyQaM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class TextGen(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size, n_layers):\n",
        "        super(TextGen, self).__init__()\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "        self.n_layers = n_layers\n",
        "        \n",
        "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
        "        self.lstm = nn.LSTM(hidden_size, hidden_size, n_layers)\n",
        "        self.out = nn.Linear(hidden_size, output_size)\n",
        "    \n",
        "    def forward(self, char_input, hidden):\n",
        "        embedded = self.embedding(char_input).view(1, 1, -1)\n",
        "        output, hidden = self.lstm(embedded, hidden)\n",
        "        output = self.out(output.view(1, -1))\n",
        "        return output, hidden\n",
        "    \n",
        "    def init_hidden(self):\n",
        "        return (torch.zeros(self.n_layers, 1, self.hidden_size).cuda(),\n",
        "                torch.zeros(self.n_layers, 1, self.hidden_size).cuda())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gTNmBU6hycZl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "hidden_size = 800\n",
        "n_layers = 1\n",
        "\n",
        "# Initialize the model\n",
        "model = TextGen(vocab.n_chars, hidden_size, vocab.n_chars, n_layers).cuda()\n",
        "\n",
        "# Loss function\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Optimizer (ADAM is a fancy version of SGD)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EYm0dfUGzMFq",
        "colab_type": "code",
        "outputId": "4f70fdeb-e6f7-4fbd-cce7-50ad36047292",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "n_epochs = 40\n",
        "print_every = 100\n",
        "loss = 0\n",
        "for e in range(1, n_epochs + 1):\n",
        "    \n",
        "    # shuffle the data before starting a new epoch\n",
        "    data_sequences_shuff = sample(data_sequences, len(data_sequences))\n",
        "    \n",
        "    for counter, sequence in enumerate(data_sequences_shuff):\n",
        "      \n",
        "      # zero gradients\n",
        "      optimizer.zero_grad()\n",
        "      \n",
        "      # creating a tensor for the input sentence\n",
        "      seq_len = len(sequence)\n",
        "      sequence_tensor = torch.LongTensor(sequence).cuda()\n",
        "      \n",
        "      # the current sentence loss\n",
        "      sentence_loss = 0\n",
        "      \n",
        "      # initialize the first hidden vector\n",
        "      hidden = model.init_hidden()\n",
        "      \n",
        "      # looping through the network char by char\n",
        "      for i in range(seq_len - 1):\n",
        "        # forward\n",
        "        output, hidden = model(sequence_tensor[i], hidden)\n",
        "        # loss\n",
        "        sentence_loss += criterion(output.view(-1).unsqueeze(0), sequence_tensor[i + 1].unsqueeze(0))\n",
        "    \n",
        "      # running backward\n",
        "      sentence_loss.backward()\n",
        "      \n",
        "      # updating weights\n",
        "      optimizer.step()\n",
        "      \n",
        "      # averaging total loss\n",
        "      loss += (sentence_loss.item() / seq_len)\n",
        "      \n",
        "      if counter % print_every == 0:\n",
        "          loss = loss / print_every\n",
        "          print('Epoch %d, %d/%d, Current Loss = %.4f' % (e, counter, len(data_sequences_shuff), loss))\n",
        "          loss = 0\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1, 0/2675, Current Loss = 0.0636\n",
            "Epoch 1, 100/2675, Current Loss = 4.3451\n",
            "Epoch 1, 200/2675, Current Loss = 3.1980\n",
            "Epoch 1, 300/2675, Current Loss = 3.0600\n",
            "Epoch 1, 400/2675, Current Loss = 2.8650\n",
            "Epoch 1, 500/2675, Current Loss = 2.7675\n",
            "Epoch 1, 600/2675, Current Loss = 2.6656\n",
            "Epoch 1, 700/2675, Current Loss = 2.7410\n",
            "Epoch 1, 800/2675, Current Loss = 2.6136\n",
            "Epoch 1, 900/2675, Current Loss = 2.6831\n",
            "Epoch 1, 1000/2675, Current Loss = 2.5316\n",
            "Epoch 1, 1100/2675, Current Loss = 2.5372\n",
            "Epoch 1, 1200/2675, Current Loss = 2.6855\n",
            "Epoch 1, 1300/2675, Current Loss = 2.4685\n",
            "Epoch 1, 1400/2675, Current Loss = 2.4446\n",
            "Epoch 1, 1500/2675, Current Loss = 2.4199\n",
            "Epoch 1, 1600/2675, Current Loss = 2.3755\n",
            "Epoch 1, 1700/2675, Current Loss = 2.4921\n",
            "Epoch 1, 1800/2675, Current Loss = 2.3934\n",
            "Epoch 1, 1900/2675, Current Loss = 2.4263\n",
            "Epoch 1, 2000/2675, Current Loss = 2.3745\n",
            "Epoch 1, 2100/2675, Current Loss = 2.3722\n",
            "Epoch 1, 2200/2675, Current Loss = 2.2691\n",
            "Epoch 1, 2300/2675, Current Loss = 2.3342\n",
            "Epoch 1, 2400/2675, Current Loss = 2.2245\n",
            "Epoch 1, 2500/2675, Current Loss = 2.4377\n",
            "Epoch 1, 2600/2675, Current Loss = 2.2809\n",
            "Epoch 2, 0/2675, Current Loss = 1.7604\n",
            "Epoch 2, 100/2675, Current Loss = 2.2841\n",
            "Epoch 2, 200/2675, Current Loss = 2.2372\n",
            "Epoch 2, 300/2675, Current Loss = 2.2720\n",
            "Epoch 2, 400/2675, Current Loss = 2.2300\n",
            "Epoch 2, 500/2675, Current Loss = 2.1911\n",
            "Epoch 2, 600/2675, Current Loss = 2.2307\n",
            "Epoch 2, 700/2675, Current Loss = 2.2753\n",
            "Epoch 2, 800/2675, Current Loss = 2.2021\n",
            "Epoch 2, 900/2675, Current Loss = 2.2156\n",
            "Epoch 2, 1000/2675, Current Loss = 2.1685\n",
            "Epoch 2, 1100/2675, Current Loss = 2.0924\n",
            "Epoch 2, 1200/2675, Current Loss = 2.1929\n",
            "Epoch 2, 1300/2675, Current Loss = 2.1629\n",
            "Epoch 2, 1400/2675, Current Loss = 2.2369\n",
            "Epoch 2, 1500/2675, Current Loss = 2.1279\n",
            "Epoch 2, 1600/2675, Current Loss = 2.1893\n",
            "Epoch 2, 1700/2675, Current Loss = 2.1132\n",
            "Epoch 2, 1800/2675, Current Loss = 2.0950\n",
            "Epoch 2, 1900/2675, Current Loss = 2.1720\n",
            "Epoch 2, 2000/2675, Current Loss = 2.2822\n",
            "Epoch 2, 2100/2675, Current Loss = 2.1222\n",
            "Epoch 2, 2200/2675, Current Loss = 2.1846\n",
            "Epoch 2, 2300/2675, Current Loss = 2.1089\n",
            "Epoch 2, 2400/2675, Current Loss = 2.0352\n",
            "Epoch 2, 2500/2675, Current Loss = 2.0916\n",
            "Epoch 2, 2600/2675, Current Loss = 2.1632\n",
            "Epoch 3, 0/2675, Current Loss = 1.6888\n",
            "Epoch 3, 100/2675, Current Loss = 1.9952\n",
            "Epoch 3, 200/2675, Current Loss = 2.1508\n",
            "Epoch 3, 300/2675, Current Loss = 2.0745\n",
            "Epoch 3, 400/2675, Current Loss = 2.0381\n",
            "Epoch 3, 500/2675, Current Loss = 2.0329\n",
            "Epoch 3, 600/2675, Current Loss = 2.0352\n",
            "Epoch 3, 700/2675, Current Loss = 2.0564\n",
            "Epoch 3, 800/2675, Current Loss = 1.9805\n",
            "Epoch 3, 900/2675, Current Loss = 2.0539\n",
            "Epoch 3, 1000/2675, Current Loss = 2.1802\n",
            "Epoch 3, 1100/2675, Current Loss = 2.0732\n",
            "Epoch 3, 1200/2675, Current Loss = 1.9799\n",
            "Epoch 3, 1300/2675, Current Loss = 2.1584\n",
            "Epoch 3, 1400/2675, Current Loss = 2.0691\n",
            "Epoch 3, 1500/2675, Current Loss = 1.9957\n",
            "Epoch 3, 1600/2675, Current Loss = 1.9797\n",
            "Epoch 3, 1700/2675, Current Loss = 2.0250\n",
            "Epoch 3, 1800/2675, Current Loss = 2.0024\n",
            "Epoch 3, 1900/2675, Current Loss = 2.0783\n",
            "Epoch 3, 2000/2675, Current Loss = 2.0614\n",
            "Epoch 3, 2100/2675, Current Loss = 1.9683\n",
            "Epoch 3, 2200/2675, Current Loss = 2.0030\n",
            "Epoch 3, 2300/2675, Current Loss = 1.9881\n",
            "Epoch 3, 2400/2675, Current Loss = 2.0601\n",
            "Epoch 3, 2500/2675, Current Loss = 2.1094\n",
            "Epoch 3, 2600/2675, Current Loss = 1.9529\n",
            "Epoch 4, 0/2675, Current Loss = 1.4372\n",
            "Epoch 4, 100/2675, Current Loss = 1.9690\n",
            "Epoch 4, 200/2675, Current Loss = 1.8487\n",
            "Epoch 4, 300/2675, Current Loss = 1.9862\n",
            "Epoch 4, 400/2675, Current Loss = 1.8534\n",
            "Epoch 4, 500/2675, Current Loss = 1.9485\n",
            "Epoch 4, 600/2675, Current Loss = 1.9213\n",
            "Epoch 4, 700/2675, Current Loss = 1.9587\n",
            "Epoch 4, 800/2675, Current Loss = 1.9472\n",
            "Epoch 4, 900/2675, Current Loss = 1.9489\n",
            "Epoch 4, 1000/2675, Current Loss = 1.8886\n",
            "Epoch 4, 1100/2675, Current Loss = 2.0112\n",
            "Epoch 4, 1200/2675, Current Loss = 2.0703\n",
            "Epoch 4, 1300/2675, Current Loss = 2.0161\n",
            "Epoch 4, 1400/2675, Current Loss = 1.9329\n",
            "Epoch 4, 1500/2675, Current Loss = 1.9091\n",
            "Epoch 4, 1600/2675, Current Loss = 1.8916\n",
            "Epoch 4, 1700/2675, Current Loss = 1.8724\n",
            "Epoch 4, 1800/2675, Current Loss = 1.9411\n",
            "Epoch 4, 1900/2675, Current Loss = 1.9594\n",
            "Epoch 4, 2000/2675, Current Loss = 1.9433\n",
            "Epoch 4, 2100/2675, Current Loss = 1.8650\n",
            "Epoch 4, 2200/2675, Current Loss = 1.8794\n",
            "Epoch 4, 2300/2675, Current Loss = 1.9105\n",
            "Epoch 4, 2400/2675, Current Loss = 1.9883\n",
            "Epoch 4, 2500/2675, Current Loss = 1.9634\n",
            "Epoch 4, 2600/2675, Current Loss = 1.9607\n",
            "Epoch 5, 0/2675, Current Loss = 1.4865\n",
            "Epoch 5, 100/2675, Current Loss = 1.8802\n",
            "Epoch 5, 200/2675, Current Loss = 1.8756\n",
            "Epoch 5, 300/2675, Current Loss = 1.8046\n",
            "Epoch 5, 400/2675, Current Loss = 1.8292\n",
            "Epoch 5, 500/2675, Current Loss = 1.8903\n",
            "Epoch 5, 600/2675, Current Loss = 1.8944\n",
            "Epoch 5, 700/2675, Current Loss = 1.8418\n",
            "Epoch 5, 800/2675, Current Loss = 1.8438\n",
            "Epoch 5, 900/2675, Current Loss = 1.8425\n",
            "Epoch 5, 1000/2675, Current Loss = 1.8994\n",
            "Epoch 5, 1100/2675, Current Loss = 1.8007\n",
            "Epoch 5, 1200/2675, Current Loss = 1.9044\n",
            "Epoch 5, 1300/2675, Current Loss = 1.8889\n",
            "Epoch 5, 1400/2675, Current Loss = 1.8514\n",
            "Epoch 5, 1500/2675, Current Loss = 1.8978\n",
            "Epoch 5, 1600/2675, Current Loss = 1.8533\n",
            "Epoch 5, 1700/2675, Current Loss = 1.8128\n",
            "Epoch 5, 1800/2675, Current Loss = 1.9151\n",
            "Epoch 5, 1900/2675, Current Loss = 1.9309\n",
            "Epoch 5, 2000/2675, Current Loss = 1.8728\n",
            "Epoch 5, 2100/2675, Current Loss = 1.7929\n",
            "Epoch 5, 2200/2675, Current Loss = 1.8147\n",
            "Epoch 5, 2300/2675, Current Loss = 1.8585\n",
            "Epoch 5, 2400/2675, Current Loss = 1.8377\n",
            "Epoch 5, 2500/2675, Current Loss = 1.7975\n",
            "Epoch 5, 2600/2675, Current Loss = 1.8204\n",
            "Epoch 6, 0/2675, Current Loss = 1.3946\n",
            "Epoch 6, 100/2675, Current Loss = 1.7191\n",
            "Epoch 6, 200/2675, Current Loss = 1.7147\n",
            "Epoch 6, 300/2675, Current Loss = 1.8523\n",
            "Epoch 6, 400/2675, Current Loss = 1.8240\n",
            "Epoch 6, 500/2675, Current Loss = 1.8070\n",
            "Epoch 6, 600/2675, Current Loss = 1.7298\n",
            "Epoch 6, 700/2675, Current Loss = 1.7545\n",
            "Epoch 6, 800/2675, Current Loss = 1.8037\n",
            "Epoch 6, 900/2675, Current Loss = 1.8051\n",
            "Epoch 6, 1000/2675, Current Loss = 1.8028\n",
            "Epoch 6, 1100/2675, Current Loss = 1.7817\n",
            "Epoch 6, 1200/2675, Current Loss = 1.7744\n",
            "Epoch 6, 1300/2675, Current Loss = 1.7708\n",
            "Epoch 6, 1400/2675, Current Loss = 1.7168\n",
            "Epoch 6, 1500/2675, Current Loss = 1.8082\n",
            "Epoch 6, 1600/2675, Current Loss = 1.7993\n",
            "Epoch 6, 1700/2675, Current Loss = 1.7983\n",
            "Epoch 6, 1800/2675, Current Loss = 1.6981\n",
            "Epoch 6, 1900/2675, Current Loss = 1.7930\n",
            "Epoch 6, 2000/2675, Current Loss = 1.7770\n",
            "Epoch 6, 2100/2675, Current Loss = 1.7262\n",
            "Epoch 6, 2200/2675, Current Loss = 1.8884\n",
            "Epoch 6, 2300/2675, Current Loss = 1.8050\n",
            "Epoch 6, 2400/2675, Current Loss = 1.7822\n",
            "Epoch 6, 2500/2675, Current Loss = 1.8020\n",
            "Epoch 6, 2600/2675, Current Loss = 1.7596\n",
            "Epoch 7, 0/2675, Current Loss = 1.3856\n",
            "Epoch 7, 100/2675, Current Loss = 1.7412\n",
            "Epoch 7, 200/2675, Current Loss = 1.7290\n",
            "Epoch 7, 300/2675, Current Loss = 1.6685\n",
            "Epoch 7, 400/2675, Current Loss = 1.6929\n",
            "Epoch 7, 500/2675, Current Loss = 1.6428\n",
            "Epoch 7, 600/2675, Current Loss = 1.6502\n",
            "Epoch 7, 700/2675, Current Loss = 1.6970\n",
            "Epoch 7, 800/2675, Current Loss = 1.7337\n",
            "Epoch 7, 900/2675, Current Loss = 1.6826\n",
            "Epoch 7, 1000/2675, Current Loss = 1.6683\n",
            "Epoch 7, 1100/2675, Current Loss = 1.7088\n",
            "Epoch 7, 1200/2675, Current Loss = 1.7210\n",
            "Epoch 7, 1300/2675, Current Loss = 1.7250\n",
            "Epoch 7, 1400/2675, Current Loss = 1.7754\n",
            "Epoch 7, 1500/2675, Current Loss = 1.7348\n",
            "Epoch 7, 1600/2675, Current Loss = 1.7886\n",
            "Epoch 7, 1700/2675, Current Loss = 1.7107\n",
            "Epoch 7, 1800/2675, Current Loss = 1.7667\n",
            "Epoch 7, 1900/2675, Current Loss = 1.6702\n",
            "Epoch 7, 2000/2675, Current Loss = 1.6758\n",
            "Epoch 7, 2100/2675, Current Loss = 1.6563\n",
            "Epoch 7, 2200/2675, Current Loss = 1.7084\n",
            "Epoch 7, 2300/2675, Current Loss = 1.7700\n",
            "Epoch 7, 2400/2675, Current Loss = 1.7634\n",
            "Epoch 7, 2500/2675, Current Loss = 1.7039\n",
            "Epoch 7, 2600/2675, Current Loss = 1.7280\n",
            "Epoch 8, 0/2675, Current Loss = 1.3093\n",
            "Epoch 8, 100/2675, Current Loss = 1.6181\n",
            "Epoch 8, 200/2675, Current Loss = 1.6123\n",
            "Epoch 8, 300/2675, Current Loss = 1.6956\n",
            "Epoch 8, 400/2675, Current Loss = 1.6916\n",
            "Epoch 8, 500/2675, Current Loss = 1.5318\n",
            "Epoch 8, 600/2675, Current Loss = 1.6665\n",
            "Epoch 8, 700/2675, Current Loss = 1.6513\n",
            "Epoch 8, 800/2675, Current Loss = 1.6459\n",
            "Epoch 8, 900/2675, Current Loss = 1.6188\n",
            "Epoch 8, 1000/2675, Current Loss = 1.5940\n",
            "Epoch 8, 1100/2675, Current Loss = 1.6982\n",
            "Epoch 8, 1200/2675, Current Loss = 1.6827\n",
            "Epoch 8, 1300/2675, Current Loss = 1.5928\n",
            "Epoch 8, 1400/2675, Current Loss = 1.6728\n",
            "Epoch 8, 1500/2675, Current Loss = 1.6988\n",
            "Epoch 8, 1600/2675, Current Loss = 1.6258\n",
            "Epoch 8, 1700/2675, Current Loss = 1.6365\n",
            "Epoch 8, 1800/2675, Current Loss = 1.7004\n",
            "Epoch 8, 1900/2675, Current Loss = 1.5918\n",
            "Epoch 8, 2000/2675, Current Loss = 1.7060\n",
            "Epoch 8, 2100/2675, Current Loss = 1.6268\n",
            "Epoch 8, 2200/2675, Current Loss = 1.7001\n",
            "Epoch 8, 2300/2675, Current Loss = 1.6738\n",
            "Epoch 8, 2400/2675, Current Loss = 1.6555\n",
            "Epoch 8, 2500/2675, Current Loss = 1.6857\n",
            "Epoch 8, 2600/2675, Current Loss = 1.6384\n",
            "Epoch 9, 0/2675, Current Loss = 1.2195\n",
            "Epoch 9, 100/2675, Current Loss = 1.5537\n",
            "Epoch 9, 200/2675, Current Loss = 1.5758\n",
            "Epoch 9, 300/2675, Current Loss = 1.6115\n",
            "Epoch 9, 400/2675, Current Loss = 1.5872\n",
            "Epoch 9, 500/2675, Current Loss = 1.5893\n",
            "Epoch 9, 600/2675, Current Loss = 1.4907\n",
            "Epoch 9, 700/2675, Current Loss = 1.5826\n",
            "Epoch 9, 800/2675, Current Loss = 1.6173\n",
            "Epoch 9, 900/2675, Current Loss = 1.6331\n",
            "Epoch 9, 1000/2675, Current Loss = 1.5759\n",
            "Epoch 9, 1100/2675, Current Loss = 1.6954\n",
            "Epoch 9, 1200/2675, Current Loss = 1.6126\n",
            "Epoch 9, 1300/2675, Current Loss = 1.5692\n",
            "Epoch 9, 1400/2675, Current Loss = 1.5790\n",
            "Epoch 9, 1500/2675, Current Loss = 1.5801\n",
            "Epoch 9, 1600/2675, Current Loss = 1.6171\n",
            "Epoch 9, 1700/2675, Current Loss = 1.6099\n",
            "Epoch 9, 1800/2675, Current Loss = 1.5498\n",
            "Epoch 9, 1900/2675, Current Loss = 1.6007\n",
            "Epoch 9, 2000/2675, Current Loss = 1.5593\n",
            "Epoch 9, 2100/2675, Current Loss = 1.5640\n",
            "Epoch 9, 2200/2675, Current Loss = 1.5230\n",
            "Epoch 9, 2300/2675, Current Loss = 1.6034\n",
            "Epoch 9, 2400/2675, Current Loss = 1.5617\n",
            "Epoch 9, 2500/2675, Current Loss = 1.6318\n",
            "Epoch 9, 2600/2675, Current Loss = 1.6473\n",
            "Epoch 10, 0/2675, Current Loss = 1.2350\n",
            "Epoch 10, 100/2675, Current Loss = 1.5438\n",
            "Epoch 10, 200/2675, Current Loss = 1.4664\n",
            "Epoch 10, 300/2675, Current Loss = 1.5227\n",
            "Epoch 10, 400/2675, Current Loss = 1.5102\n",
            "Epoch 10, 500/2675, Current Loss = 1.4978\n",
            "Epoch 10, 600/2675, Current Loss = 1.5001\n",
            "Epoch 10, 700/2675, Current Loss = 1.4854\n",
            "Epoch 10, 800/2675, Current Loss = 1.5011\n",
            "Epoch 10, 900/2675, Current Loss = 1.4543\n",
            "Epoch 10, 1000/2675, Current Loss = 1.4974\n",
            "Epoch 10, 1100/2675, Current Loss = 1.5663\n",
            "Epoch 10, 1200/2675, Current Loss = 1.4936\n",
            "Epoch 10, 1300/2675, Current Loss = 1.4955\n",
            "Epoch 10, 1400/2675, Current Loss = 1.5475\n",
            "Epoch 10, 1500/2675, Current Loss = 1.5272\n",
            "Epoch 10, 1600/2675, Current Loss = 1.5528\n",
            "Epoch 10, 1700/2675, Current Loss = 1.4848\n",
            "Epoch 10, 1800/2675, Current Loss = 1.5300\n",
            "Epoch 10, 1900/2675, Current Loss = 1.5725\n",
            "Epoch 10, 2000/2675, Current Loss = 1.6093\n",
            "Epoch 10, 2100/2675, Current Loss = 1.5082\n",
            "Epoch 10, 2200/2675, Current Loss = 1.4967\n",
            "Epoch 10, 2300/2675, Current Loss = 1.5390\n",
            "Epoch 10, 2400/2675, Current Loss = 1.5759\n",
            "Epoch 10, 2500/2675, Current Loss = 1.6404\n",
            "Epoch 10, 2600/2675, Current Loss = 1.6579\n",
            "Epoch 11, 0/2675, Current Loss = 1.1474\n",
            "Epoch 11, 100/2675, Current Loss = 1.4928\n",
            "Epoch 11, 200/2675, Current Loss = 1.4272\n",
            "Epoch 11, 300/2675, Current Loss = 1.4971\n",
            "Epoch 11, 400/2675, Current Loss = 1.3867\n",
            "Epoch 11, 500/2675, Current Loss = 1.4331\n",
            "Epoch 11, 600/2675, Current Loss = 1.5160\n",
            "Epoch 11, 700/2675, Current Loss = 1.4781\n",
            "Epoch 11, 800/2675, Current Loss = 1.4816\n",
            "Epoch 11, 900/2675, Current Loss = 1.4665\n",
            "Epoch 11, 1000/2675, Current Loss = 1.5034\n",
            "Epoch 11, 1100/2675, Current Loss = 1.5266\n",
            "Epoch 11, 1200/2675, Current Loss = 1.4442\n",
            "Epoch 11, 1300/2675, Current Loss = 1.4304\n",
            "Epoch 11, 1400/2675, Current Loss = 1.4559\n",
            "Epoch 11, 1500/2675, Current Loss = 1.4594\n",
            "Epoch 11, 1600/2675, Current Loss = 1.4832\n",
            "Epoch 11, 1700/2675, Current Loss = 1.4834\n",
            "Epoch 11, 1800/2675, Current Loss = 1.4222\n",
            "Epoch 11, 1900/2675, Current Loss = 1.5240\n",
            "Epoch 11, 2000/2675, Current Loss = 1.5023\n",
            "Epoch 11, 2100/2675, Current Loss = 1.4699\n",
            "Epoch 11, 2200/2675, Current Loss = 1.4365\n",
            "Epoch 11, 2300/2675, Current Loss = 1.4516\n",
            "Epoch 11, 2400/2675, Current Loss = 1.4636\n",
            "Epoch 11, 2500/2675, Current Loss = 1.4870\n",
            "Epoch 11, 2600/2675, Current Loss = 1.4705\n",
            "Epoch 12, 0/2675, Current Loss = 1.1370\n",
            "Epoch 12, 100/2675, Current Loss = 1.3782\n",
            "Epoch 12, 200/2675, Current Loss = 1.3984\n",
            "Epoch 12, 300/2675, Current Loss = 1.4105\n",
            "Epoch 12, 400/2675, Current Loss = 1.3686\n",
            "Epoch 12, 500/2675, Current Loss = 1.3659\n",
            "Epoch 12, 600/2675, Current Loss = 1.5135\n",
            "Epoch 12, 700/2675, Current Loss = 1.3429\n",
            "Epoch 12, 800/2675, Current Loss = 1.4345\n",
            "Epoch 12, 900/2675, Current Loss = 1.3982\n",
            "Epoch 12, 1000/2675, Current Loss = 1.4571\n",
            "Epoch 12, 1100/2675, Current Loss = 1.4109\n",
            "Epoch 12, 1200/2675, Current Loss = 1.4012\n",
            "Epoch 12, 1300/2675, Current Loss = 1.4076\n",
            "Epoch 12, 1400/2675, Current Loss = 1.5323\n",
            "Epoch 12, 1500/2675, Current Loss = 1.3503\n",
            "Epoch 12, 1600/2675, Current Loss = 1.4727\n",
            "Epoch 12, 1700/2675, Current Loss = 1.4302\n",
            "Epoch 12, 1800/2675, Current Loss = 1.4277\n",
            "Epoch 12, 1900/2675, Current Loss = 1.4689\n",
            "Epoch 12, 2000/2675, Current Loss = 1.4159\n",
            "Epoch 12, 2100/2675, Current Loss = 1.3540\n",
            "Epoch 12, 2200/2675, Current Loss = 1.4112\n",
            "Epoch 12, 2300/2675, Current Loss = 1.3955\n",
            "Epoch 12, 2400/2675, Current Loss = 1.4482\n",
            "Epoch 12, 2500/2675, Current Loss = 1.4093\n",
            "Epoch 12, 2600/2675, Current Loss = 1.4346\n",
            "Epoch 13, 0/2675, Current Loss = 1.0313\n",
            "Epoch 13, 100/2675, Current Loss = 1.3395\n",
            "Epoch 13, 200/2675, Current Loss = 1.3037\n",
            "Epoch 13, 300/2675, Current Loss = 1.3141\n",
            "Epoch 13, 400/2675, Current Loss = 1.3701\n",
            "Epoch 13, 500/2675, Current Loss = 1.3625\n",
            "Epoch 13, 600/2675, Current Loss = 1.3681\n",
            "Epoch 13, 700/2675, Current Loss = 1.3854\n",
            "Epoch 13, 800/2675, Current Loss = 1.3487\n",
            "Epoch 13, 900/2675, Current Loss = 1.3404\n",
            "Epoch 13, 1000/2675, Current Loss = 1.4129\n",
            "Epoch 13, 1100/2675, Current Loss = 1.4454\n",
            "Epoch 13, 1200/2675, Current Loss = 1.3071\n",
            "Epoch 13, 1300/2675, Current Loss = 1.3022\n",
            "Epoch 13, 1400/2675, Current Loss = 1.3317\n",
            "Epoch 13, 1500/2675, Current Loss = 1.3765\n",
            "Epoch 13, 1600/2675, Current Loss = 1.3739\n",
            "Epoch 13, 1700/2675, Current Loss = 1.3792\n",
            "Epoch 13, 1800/2675, Current Loss = 1.3349\n",
            "Epoch 13, 1900/2675, Current Loss = 1.3717\n",
            "Epoch 13, 2000/2675, Current Loss = 1.3866\n",
            "Epoch 13, 2100/2675, Current Loss = 1.2667\n",
            "Epoch 13, 2200/2675, Current Loss = 1.4049\n",
            "Epoch 13, 2300/2675, Current Loss = 1.3965\n",
            "Epoch 13, 2400/2675, Current Loss = 1.3192\n",
            "Epoch 13, 2500/2675, Current Loss = 1.3732\n",
            "Epoch 13, 2600/2675, Current Loss = 1.3659\n",
            "Epoch 14, 0/2675, Current Loss = 1.0527\n",
            "Epoch 14, 100/2675, Current Loss = 1.3170\n",
            "Epoch 14, 200/2675, Current Loss = 1.2593\n",
            "Epoch 14, 300/2675, Current Loss = 1.2737\n",
            "Epoch 14, 400/2675, Current Loss = 1.2052\n",
            "Epoch 14, 500/2675, Current Loss = 1.2668\n",
            "Epoch 14, 600/2675, Current Loss = 1.3379\n",
            "Epoch 14, 700/2675, Current Loss = 1.2605\n",
            "Epoch 14, 800/2675, Current Loss = 1.2972\n",
            "Epoch 14, 900/2675, Current Loss = 1.2171\n",
            "Epoch 14, 1000/2675, Current Loss = 1.2964\n",
            "Epoch 14, 1100/2675, Current Loss = 1.3470\n",
            "Epoch 14, 1200/2675, Current Loss = 1.3143\n",
            "Epoch 14, 1300/2675, Current Loss = 1.2648\n",
            "Epoch 14, 1400/2675, Current Loss = 1.3838\n",
            "Epoch 14, 1500/2675, Current Loss = 1.3200\n",
            "Epoch 14, 1600/2675, Current Loss = 1.3752\n",
            "Epoch 14, 1700/2675, Current Loss = 1.2925\n",
            "Epoch 14, 1800/2675, Current Loss = 1.2977\n",
            "Epoch 14, 1900/2675, Current Loss = 1.2766\n",
            "Epoch 14, 2000/2675, Current Loss = 1.2713\n",
            "Epoch 14, 2100/2675, Current Loss = 1.3562\n",
            "Epoch 14, 2200/2675, Current Loss = 1.2955\n",
            "Epoch 14, 2300/2675, Current Loss = 1.3496\n",
            "Epoch 14, 2400/2675, Current Loss = 1.3555\n",
            "Epoch 14, 2500/2675, Current Loss = 1.3144\n",
            "Epoch 14, 2600/2675, Current Loss = 1.3270\n",
            "Epoch 15, 0/2675, Current Loss = 0.9941\n",
            "Epoch 15, 100/2675, Current Loss = 1.1770\n",
            "Epoch 15, 200/2675, Current Loss = 1.2025\n",
            "Epoch 15, 300/2675, Current Loss = 1.2528\n",
            "Epoch 15, 400/2675, Current Loss = 1.1992\n",
            "Epoch 15, 500/2675, Current Loss = 1.2128\n",
            "Epoch 15, 600/2675, Current Loss = 1.2328\n",
            "Epoch 15, 700/2675, Current Loss = 1.2801\n",
            "Epoch 15, 800/2675, Current Loss = 1.2297\n",
            "Epoch 15, 900/2675, Current Loss = 1.2733\n",
            "Epoch 15, 1000/2675, Current Loss = 1.2588\n",
            "Epoch 15, 1100/2675, Current Loss = 1.1730\n",
            "Epoch 15, 1200/2675, Current Loss = 1.2040\n",
            "Epoch 15, 1300/2675, Current Loss = 1.2523\n",
            "Epoch 15, 1400/2675, Current Loss = 1.2636\n",
            "Epoch 15, 1500/2675, Current Loss = 1.2636\n",
            "Epoch 15, 1600/2675, Current Loss = 1.2210\n",
            "Epoch 15, 1700/2675, Current Loss = 1.2637\n",
            "Epoch 15, 1800/2675, Current Loss = 1.2188\n",
            "Epoch 15, 1900/2675, Current Loss = 1.3246\n",
            "Epoch 15, 2000/2675, Current Loss = 1.2657\n",
            "Epoch 15, 2100/2675, Current Loss = 1.2766\n",
            "Epoch 15, 2200/2675, Current Loss = 1.2667\n",
            "Epoch 15, 2300/2675, Current Loss = 1.2672\n",
            "Epoch 15, 2400/2675, Current Loss = 1.3283\n",
            "Epoch 15, 2500/2675, Current Loss = 1.2477\n",
            "Epoch 15, 2600/2675, Current Loss = 1.3161\n",
            "Epoch 16, 0/2675, Current Loss = 0.9141\n",
            "Epoch 16, 100/2675, Current Loss = 1.1872\n",
            "Epoch 16, 200/2675, Current Loss = 1.1071\n",
            "Epoch 16, 300/2675, Current Loss = 1.1738\n",
            "Epoch 16, 400/2675, Current Loss = 1.1257\n",
            "Epoch 16, 500/2675, Current Loss = 1.2003\n",
            "Epoch 16, 600/2675, Current Loss = 1.1461\n",
            "Epoch 16, 700/2675, Current Loss = 1.1437\n",
            "Epoch 16, 800/2675, Current Loss = 1.1553\n",
            "Epoch 16, 900/2675, Current Loss = 1.1711\n",
            "Epoch 16, 1000/2675, Current Loss = 1.1802\n",
            "Epoch 16, 1100/2675, Current Loss = 1.2599\n",
            "Epoch 16, 1200/2675, Current Loss = 1.1725\n",
            "Epoch 16, 1300/2675, Current Loss = 1.1963\n",
            "Epoch 16, 1400/2675, Current Loss = 1.2432\n",
            "Epoch 16, 1500/2675, Current Loss = 1.2359\n",
            "Epoch 16, 1600/2675, Current Loss = 1.2630\n",
            "Epoch 16, 1700/2675, Current Loss = 1.1965\n",
            "Epoch 16, 1800/2675, Current Loss = 1.2448\n",
            "Epoch 16, 1900/2675, Current Loss = 1.2145\n",
            "Epoch 16, 2000/2675, Current Loss = 1.1846\n",
            "Epoch 16, 2100/2675, Current Loss = 1.2535\n",
            "Epoch 16, 2200/2675, Current Loss = 1.1488\n",
            "Epoch 16, 2300/2675, Current Loss = 1.2843\n",
            "Epoch 16, 2400/2675, Current Loss = 1.1716\n",
            "Epoch 16, 2500/2675, Current Loss = 1.2158\n",
            "Epoch 16, 2600/2675, Current Loss = 1.1539\n",
            "Epoch 17, 0/2675, Current Loss = 0.8823\n",
            "Epoch 17, 100/2675, Current Loss = 1.0992\n",
            "Epoch 17, 200/2675, Current Loss = 1.1740\n",
            "Epoch 17, 300/2675, Current Loss = 1.1157\n",
            "Epoch 17, 400/2675, Current Loss = 1.1108\n",
            "Epoch 17, 500/2675, Current Loss = 1.1716\n",
            "Epoch 17, 600/2675, Current Loss = 1.1802\n",
            "Epoch 17, 700/2675, Current Loss = 1.0601\n",
            "Epoch 17, 800/2675, Current Loss = 1.2005\n",
            "Epoch 17, 900/2675, Current Loss = 1.1498\n",
            "Epoch 17, 1000/2675, Current Loss = 1.1732\n",
            "Epoch 17, 1100/2675, Current Loss = 1.1174\n",
            "Epoch 17, 1200/2675, Current Loss = 1.1183\n",
            "Epoch 17, 1300/2675, Current Loss = 1.0956\n",
            "Epoch 17, 1400/2675, Current Loss = 1.0878\n",
            "Epoch 17, 1500/2675, Current Loss = 1.0950\n",
            "Epoch 17, 1600/2675, Current Loss = 1.1004\n",
            "Epoch 17, 1700/2675, Current Loss = 1.1987\n",
            "Epoch 17, 1800/2675, Current Loss = 1.1889\n",
            "Epoch 17, 1900/2675, Current Loss = 1.0735\n",
            "Epoch 17, 2000/2675, Current Loss = 1.1438\n",
            "Epoch 17, 2100/2675, Current Loss = 1.1576\n",
            "Epoch 17, 2200/2675, Current Loss = 1.2232\n",
            "Epoch 17, 2300/2675, Current Loss = 1.1391\n",
            "Epoch 17, 2400/2675, Current Loss = 1.1674\n",
            "Epoch 17, 2500/2675, Current Loss = 1.1551\n",
            "Epoch 17, 2600/2675, Current Loss = 1.1702\n",
            "Epoch 18, 0/2675, Current Loss = 0.8610\n",
            "Epoch 18, 100/2675, Current Loss = 1.0455\n",
            "Epoch 18, 200/2675, Current Loss = 1.0450\n",
            "Epoch 18, 300/2675, Current Loss = 1.0349\n",
            "Epoch 18, 400/2675, Current Loss = 1.0827\n",
            "Epoch 18, 500/2675, Current Loss = 1.0398\n",
            "Epoch 18, 600/2675, Current Loss = 1.0744\n",
            "Epoch 18, 700/2675, Current Loss = 1.0873\n",
            "Epoch 18, 800/2675, Current Loss = 1.0673\n",
            "Epoch 18, 900/2675, Current Loss = 1.1203\n",
            "Epoch 18, 1000/2675, Current Loss = 1.0827\n",
            "Epoch 18, 1100/2675, Current Loss = 1.0619\n",
            "Epoch 18, 1200/2675, Current Loss = 1.1121\n",
            "Epoch 18, 1300/2675, Current Loss = 1.1313\n",
            "Epoch 18, 1400/2675, Current Loss = 1.0427\n",
            "Epoch 18, 1500/2675, Current Loss = 1.0345\n",
            "Epoch 18, 1600/2675, Current Loss = 1.1266\n",
            "Epoch 18, 1700/2675, Current Loss = 1.1237\n",
            "Epoch 18, 1800/2675, Current Loss = 1.1595\n",
            "Epoch 18, 1900/2675, Current Loss = 1.0871\n",
            "Epoch 18, 2000/2675, Current Loss = 1.0494\n",
            "Epoch 18, 2100/2675, Current Loss = 1.0953\n",
            "Epoch 18, 2200/2675, Current Loss = 1.1200\n",
            "Epoch 18, 2300/2675, Current Loss = 1.1243\n",
            "Epoch 18, 2400/2675, Current Loss = 1.1205\n",
            "Epoch 18, 2500/2675, Current Loss = 1.0598\n",
            "Epoch 18, 2600/2675, Current Loss = 1.1890\n",
            "Epoch 19, 0/2675, Current Loss = 0.8215\n",
            "Epoch 19, 100/2675, Current Loss = 1.0114\n",
            "Epoch 19, 200/2675, Current Loss = 0.9732\n",
            "Epoch 19, 300/2675, Current Loss = 0.9695\n",
            "Epoch 19, 400/2675, Current Loss = 1.0024\n",
            "Epoch 19, 500/2675, Current Loss = 1.0319\n",
            "Epoch 19, 600/2675, Current Loss = 0.9982\n",
            "Epoch 19, 700/2675, Current Loss = 1.0615\n",
            "Epoch 19, 800/2675, Current Loss = 1.0082\n",
            "Epoch 19, 900/2675, Current Loss = 1.0643\n",
            "Epoch 19, 1000/2675, Current Loss = 1.0239\n",
            "Epoch 19, 1100/2675, Current Loss = 1.0305\n",
            "Epoch 19, 1200/2675, Current Loss = 1.0592\n",
            "Epoch 19, 1300/2675, Current Loss = 1.0051\n",
            "Epoch 19, 1400/2675, Current Loss = 1.0665\n",
            "Epoch 19, 1500/2675, Current Loss = 1.0008\n",
            "Epoch 19, 1600/2675, Current Loss = 1.0819\n",
            "Epoch 19, 1700/2675, Current Loss = 0.9633\n",
            "Epoch 19, 1800/2675, Current Loss = 1.0582\n",
            "Epoch 19, 1900/2675, Current Loss = 1.0536\n",
            "Epoch 19, 2000/2675, Current Loss = 1.0037\n",
            "Epoch 19, 2100/2675, Current Loss = 1.0857\n",
            "Epoch 19, 2200/2675, Current Loss = 1.0242\n",
            "Epoch 19, 2300/2675, Current Loss = 1.0583\n",
            "Epoch 19, 2400/2675, Current Loss = 1.0834\n",
            "Epoch 19, 2500/2675, Current Loss = 1.0306\n",
            "Epoch 19, 2600/2675, Current Loss = 1.0680\n",
            "Epoch 20, 0/2675, Current Loss = 0.8525\n",
            "Epoch 20, 100/2675, Current Loss = 0.9069\n",
            "Epoch 20, 200/2675, Current Loss = 0.9591\n",
            "Epoch 20, 300/2675, Current Loss = 0.9359\n",
            "Epoch 20, 400/2675, Current Loss = 0.9640\n",
            "Epoch 20, 500/2675, Current Loss = 0.9303\n",
            "Epoch 20, 600/2675, Current Loss = 0.9684\n",
            "Epoch 20, 700/2675, Current Loss = 0.9230\n",
            "Epoch 20, 800/2675, Current Loss = 0.9743\n",
            "Epoch 20, 900/2675, Current Loss = 1.0235\n",
            "Epoch 20, 1000/2675, Current Loss = 0.9993\n",
            "Epoch 20, 1100/2675, Current Loss = 1.0324\n",
            "Epoch 20, 1200/2675, Current Loss = 0.9735\n",
            "Epoch 20, 1300/2675, Current Loss = 1.0392\n",
            "Epoch 20, 1400/2675, Current Loss = 0.9781\n",
            "Epoch 20, 1500/2675, Current Loss = 0.9786\n",
            "Epoch 20, 1600/2675, Current Loss = 0.9438\n",
            "Epoch 20, 1700/2675, Current Loss = 0.9696\n",
            "Epoch 20, 1800/2675, Current Loss = 1.0100\n",
            "Epoch 20, 1900/2675, Current Loss = 0.9880\n",
            "Epoch 20, 2000/2675, Current Loss = 0.9918\n",
            "Epoch 20, 2100/2675, Current Loss = 1.0137\n",
            "Epoch 20, 2200/2675, Current Loss = 1.0022\n",
            "Epoch 20, 2300/2675, Current Loss = 1.0187\n",
            "Epoch 20, 2400/2675, Current Loss = 1.0357\n",
            "Epoch 20, 2500/2675, Current Loss = 0.9818\n",
            "Epoch 20, 2600/2675, Current Loss = 0.9963\n",
            "Epoch 21, 0/2675, Current Loss = 0.7489\n",
            "Epoch 21, 100/2675, Current Loss = 0.8578\n",
            "Epoch 21, 200/2675, Current Loss = 0.8835\n",
            "Epoch 21, 300/2675, Current Loss = 0.8663\n",
            "Epoch 21, 400/2675, Current Loss = 0.9160\n",
            "Epoch 21, 500/2675, Current Loss = 0.9336\n",
            "Epoch 21, 600/2675, Current Loss = 0.9190\n",
            "Epoch 21, 700/2675, Current Loss = 0.9305\n",
            "Epoch 21, 800/2675, Current Loss = 0.9234\n",
            "Epoch 21, 900/2675, Current Loss = 0.9814\n",
            "Epoch 21, 1000/2675, Current Loss = 0.8892\n",
            "Epoch 21, 1100/2675, Current Loss = 0.8844\n",
            "Epoch 21, 1200/2675, Current Loss = 0.9474\n",
            "Epoch 21, 1300/2675, Current Loss = 0.9155\n",
            "Epoch 21, 1400/2675, Current Loss = 0.9803\n",
            "Epoch 21, 1500/2675, Current Loss = 0.9886\n",
            "Epoch 21, 1600/2675, Current Loss = 0.9218\n",
            "Epoch 21, 1700/2675, Current Loss = 0.9735\n",
            "Epoch 21, 1800/2675, Current Loss = 0.9567\n",
            "Epoch 21, 1900/2675, Current Loss = 0.9313\n",
            "Epoch 21, 2000/2675, Current Loss = 0.9742\n",
            "Epoch 21, 2100/2675, Current Loss = 0.9169\n",
            "Epoch 21, 2200/2675, Current Loss = 0.9341\n",
            "Epoch 21, 2300/2675, Current Loss = 0.9565\n",
            "Epoch 21, 2400/2675, Current Loss = 0.9403\n",
            "Epoch 21, 2500/2675, Current Loss = 0.9852\n",
            "Epoch 21, 2600/2675, Current Loss = 0.9180\n",
            "Epoch 22, 0/2675, Current Loss = 0.7694\n",
            "Epoch 22, 100/2675, Current Loss = 0.8626\n",
            "Epoch 22, 200/2675, Current Loss = 0.8266\n",
            "Epoch 22, 300/2675, Current Loss = 0.8627\n",
            "Epoch 22, 400/2675, Current Loss = 0.8792\n",
            "Epoch 22, 500/2675, Current Loss = 0.8409\n",
            "Epoch 22, 600/2675, Current Loss = 0.8362\n",
            "Epoch 22, 700/2675, Current Loss = 0.8597\n",
            "Epoch 22, 800/2675, Current Loss = 0.8667\n",
            "Epoch 22, 900/2675, Current Loss = 0.8898\n",
            "Epoch 22, 1000/2675, Current Loss = 0.8908\n",
            "Epoch 22, 1100/2675, Current Loss = 0.8484\n",
            "Epoch 22, 1200/2675, Current Loss = 0.9038\n",
            "Epoch 22, 1300/2675, Current Loss = 0.9046\n",
            "Epoch 22, 1400/2675, Current Loss = 0.9007\n",
            "Epoch 22, 1500/2675, Current Loss = 0.9009\n",
            "Epoch 22, 1600/2675, Current Loss = 0.8519\n",
            "Epoch 22, 1700/2675, Current Loss = 0.9028\n",
            "Epoch 22, 1800/2675, Current Loss = 0.9654\n",
            "Epoch 22, 1900/2675, Current Loss = 0.8811\n",
            "Epoch 22, 2000/2675, Current Loss = 0.8951\n",
            "Epoch 22, 2100/2675, Current Loss = 0.8907\n",
            "Epoch 22, 2200/2675, Current Loss = 0.9038\n",
            "Epoch 22, 2300/2675, Current Loss = 0.9058\n",
            "Epoch 22, 2400/2675, Current Loss = 0.8773\n",
            "Epoch 22, 2500/2675, Current Loss = 0.9239\n",
            "Epoch 22, 2600/2675, Current Loss = 0.9193\n",
            "Epoch 23, 0/2675, Current Loss = 0.6873\n",
            "Epoch 23, 100/2675, Current Loss = 0.8255\n",
            "Epoch 23, 200/2675, Current Loss = 0.7525\n",
            "Epoch 23, 300/2675, Current Loss = 0.7845\n",
            "Epoch 23, 400/2675, Current Loss = 0.8269\n",
            "Epoch 23, 500/2675, Current Loss = 0.7927\n",
            "Epoch 23, 600/2675, Current Loss = 0.8201\n",
            "Epoch 23, 700/2675, Current Loss = 0.7914\n",
            "Epoch 23, 800/2675, Current Loss = 0.8358\n",
            "Epoch 23, 900/2675, Current Loss = 0.8261\n",
            "Epoch 23, 1000/2675, Current Loss = 0.8371\n",
            "Epoch 23, 1100/2675, Current Loss = 0.8054\n",
            "Epoch 23, 1200/2675, Current Loss = 0.8404\n",
            "Epoch 23, 1300/2675, Current Loss = 0.8954\n",
            "Epoch 23, 1400/2675, Current Loss = 0.7991\n",
            "Epoch 23, 1500/2675, Current Loss = 0.8799\n",
            "Epoch 23, 1600/2675, Current Loss = 0.8705\n",
            "Epoch 23, 1700/2675, Current Loss = 0.8212\n",
            "Epoch 23, 1800/2675, Current Loss = 0.8416\n",
            "Epoch 23, 1900/2675, Current Loss = 0.8527\n",
            "Epoch 23, 2000/2675, Current Loss = 0.9295\n",
            "Epoch 23, 2100/2675, Current Loss = 0.8345\n",
            "Epoch 23, 2200/2675, Current Loss = 0.8623\n",
            "Epoch 23, 2300/2675, Current Loss = 0.8376\n",
            "Epoch 23, 2400/2675, Current Loss = 0.8115\n",
            "Epoch 23, 2500/2675, Current Loss = 0.8851\n",
            "Epoch 23, 2600/2675, Current Loss = 0.8905\n",
            "Epoch 24, 0/2675, Current Loss = 0.6313\n",
            "Epoch 24, 100/2675, Current Loss = 0.7419\n",
            "Epoch 24, 200/2675, Current Loss = 0.7747\n",
            "Epoch 24, 300/2675, Current Loss = 0.7589\n",
            "Epoch 24, 400/2675, Current Loss = 0.7286\n",
            "Epoch 24, 500/2675, Current Loss = 0.7956\n",
            "Epoch 24, 600/2675, Current Loss = 0.7938\n",
            "Epoch 24, 700/2675, Current Loss = 0.7897\n",
            "Epoch 24, 800/2675, Current Loss = 0.7537\n",
            "Epoch 24, 900/2675, Current Loss = 0.7578\n",
            "Epoch 24, 1000/2675, Current Loss = 0.7887\n",
            "Epoch 24, 1100/2675, Current Loss = 0.8058\n",
            "Epoch 24, 1200/2675, Current Loss = 0.8209\n",
            "Epoch 24, 1300/2675, Current Loss = 0.8187\n",
            "Epoch 24, 1400/2675, Current Loss = 0.8072\n",
            "Epoch 24, 1500/2675, Current Loss = 0.7547\n",
            "Epoch 24, 1600/2675, Current Loss = 0.8092\n",
            "Epoch 24, 1700/2675, Current Loss = 0.8591\n",
            "Epoch 24, 1800/2675, Current Loss = 0.7980\n",
            "Epoch 24, 1900/2675, Current Loss = 0.7587\n",
            "Epoch 24, 2000/2675, Current Loss = 0.8110\n",
            "Epoch 24, 2100/2675, Current Loss = 0.7322\n",
            "Epoch 24, 2200/2675, Current Loss = 0.8631\n",
            "Epoch 24, 2300/2675, Current Loss = 0.7834\n",
            "Epoch 24, 2400/2675, Current Loss = 0.7790\n",
            "Epoch 24, 2500/2675, Current Loss = 0.8330\n",
            "Epoch 24, 2600/2675, Current Loss = 0.8312\n",
            "Epoch 25, 0/2675, Current Loss = 0.5895\n",
            "Epoch 25, 100/2675, Current Loss = 0.6798\n",
            "Epoch 25, 200/2675, Current Loss = 0.6856\n",
            "Epoch 25, 300/2675, Current Loss = 0.7247\n",
            "Epoch 25, 400/2675, Current Loss = 0.7571\n",
            "Epoch 25, 500/2675, Current Loss = 0.7205\n",
            "Epoch 25, 600/2675, Current Loss = 0.7125\n",
            "Epoch 25, 700/2675, Current Loss = 0.7272\n",
            "Epoch 25, 800/2675, Current Loss = 0.7634\n",
            "Epoch 25, 900/2675, Current Loss = 0.7039\n",
            "Epoch 25, 1000/2675, Current Loss = 0.7384\n",
            "Epoch 25, 1100/2675, Current Loss = 0.7543\n",
            "Epoch 25, 1200/2675, Current Loss = 0.7277\n",
            "Epoch 25, 1300/2675, Current Loss = 0.7667\n",
            "Epoch 25, 1400/2675, Current Loss = 0.7543\n",
            "Epoch 25, 1500/2675, Current Loss = 0.7725\n",
            "Epoch 25, 1600/2675, Current Loss = 0.7760\n",
            "Epoch 25, 1700/2675, Current Loss = 0.7180\n",
            "Epoch 25, 1800/2675, Current Loss = 0.7615\n",
            "Epoch 25, 1900/2675, Current Loss = 0.7553\n",
            "Epoch 25, 2000/2675, Current Loss = 0.7130\n",
            "Epoch 25, 2100/2675, Current Loss = 0.7730\n",
            "Epoch 25, 2200/2675, Current Loss = 0.7456\n",
            "Epoch 25, 2300/2675, Current Loss = 0.7730\n",
            "Epoch 25, 2400/2675, Current Loss = 0.7786\n",
            "Epoch 25, 2500/2675, Current Loss = 0.7581\n",
            "Epoch 25, 2600/2675, Current Loss = 0.8137\n",
            "Epoch 26, 0/2675, Current Loss = 0.5738\n",
            "Epoch 26, 100/2675, Current Loss = 0.6752\n",
            "Epoch 26, 200/2675, Current Loss = 0.6582\n",
            "Epoch 26, 300/2675, Current Loss = 0.6733\n",
            "Epoch 26, 400/2675, Current Loss = 0.6773\n",
            "Epoch 26, 500/2675, Current Loss = 0.6961\n",
            "Epoch 26, 600/2675, Current Loss = 0.6806\n",
            "Epoch 26, 700/2675, Current Loss = 0.6965\n",
            "Epoch 26, 800/2675, Current Loss = 0.6672\n",
            "Epoch 26, 900/2675, Current Loss = 0.6676\n",
            "Epoch 26, 1000/2675, Current Loss = 0.7061\n",
            "Epoch 26, 1100/2675, Current Loss = 0.7045\n",
            "Epoch 26, 1200/2675, Current Loss = 0.6980\n",
            "Epoch 26, 1300/2675, Current Loss = 0.6874\n",
            "Epoch 26, 1400/2675, Current Loss = 0.6727\n",
            "Epoch 26, 1500/2675, Current Loss = 0.6904\n",
            "Epoch 26, 1600/2675, Current Loss = 0.6772\n",
            "Epoch 26, 1700/2675, Current Loss = 0.7558\n",
            "Epoch 26, 1800/2675, Current Loss = 0.7009\n",
            "Epoch 26, 1900/2675, Current Loss = 0.7147\n",
            "Epoch 26, 2000/2675, Current Loss = 0.7800\n",
            "Epoch 26, 2100/2675, Current Loss = 0.6991\n",
            "Epoch 26, 2200/2675, Current Loss = 0.6882\n",
            "Epoch 26, 2300/2675, Current Loss = 0.7558\n",
            "Epoch 26, 2400/2675, Current Loss = 0.7507\n",
            "Epoch 26, 2500/2675, Current Loss = 0.7500\n",
            "Epoch 26, 2600/2675, Current Loss = 0.7425\n",
            "Epoch 27, 0/2675, Current Loss = 0.5370\n",
            "Epoch 27, 100/2675, Current Loss = 0.6196\n",
            "Epoch 27, 200/2675, Current Loss = 0.5846\n",
            "Epoch 27, 300/2675, Current Loss = 0.6104\n",
            "Epoch 27, 400/2675, Current Loss = 0.6031\n",
            "Epoch 27, 500/2675, Current Loss = 0.6121\n",
            "Epoch 27, 600/2675, Current Loss = 0.6904\n",
            "Epoch 27, 700/2675, Current Loss = 0.6130\n",
            "Epoch 27, 800/2675, Current Loss = 0.6679\n",
            "Epoch 27, 900/2675, Current Loss = 0.6446\n",
            "Epoch 27, 1000/2675, Current Loss = 0.6754\n",
            "Epoch 27, 1100/2675, Current Loss = 0.6865\n",
            "Epoch 27, 1200/2675, Current Loss = 0.6667\n",
            "Epoch 27, 1300/2675, Current Loss = 0.6710\n",
            "Epoch 27, 1400/2675, Current Loss = 0.7119\n",
            "Epoch 27, 1500/2675, Current Loss = 0.6504\n",
            "Epoch 27, 1600/2675, Current Loss = 0.6386\n",
            "Epoch 27, 1700/2675, Current Loss = 0.7005\n",
            "Epoch 27, 1800/2675, Current Loss = 0.7109\n",
            "Epoch 27, 1900/2675, Current Loss = 0.6999\n",
            "Epoch 27, 2000/2675, Current Loss = 0.6467\n",
            "Epoch 27, 2100/2675, Current Loss = 0.6957\n",
            "Epoch 27, 2200/2675, Current Loss = 0.6928\n",
            "Epoch 27, 2300/2675, Current Loss = 0.6688\n",
            "Epoch 27, 2400/2675, Current Loss = 0.6765\n",
            "Epoch 27, 2500/2675, Current Loss = 0.6556\n",
            "Epoch 27, 2600/2675, Current Loss = 0.6824\n",
            "Epoch 28, 0/2675, Current Loss = 0.5212\n",
            "Epoch 28, 100/2675, Current Loss = 0.5748\n",
            "Epoch 28, 200/2675, Current Loss = 0.6251\n",
            "Epoch 28, 300/2675, Current Loss = 0.5684\n",
            "Epoch 28, 400/2675, Current Loss = 0.5769\n",
            "Epoch 28, 500/2675, Current Loss = 0.5815\n",
            "Epoch 28, 600/2675, Current Loss = 0.6105\n",
            "Epoch 28, 700/2675, Current Loss = 0.5987\n",
            "Epoch 28, 800/2675, Current Loss = 0.6045\n",
            "Epoch 28, 900/2675, Current Loss = 0.6261\n",
            "Epoch 28, 1000/2675, Current Loss = 0.6139\n",
            "Epoch 28, 1100/2675, Current Loss = 0.6163\n",
            "Epoch 28, 1200/2675, Current Loss = 0.6455\n",
            "Epoch 28, 1300/2675, Current Loss = 0.6080\n",
            "Epoch 28, 1400/2675, Current Loss = 0.6275\n",
            "Epoch 28, 1500/2675, Current Loss = 0.6074\n",
            "Epoch 28, 1600/2675, Current Loss = 0.6131\n",
            "Epoch 28, 1700/2675, Current Loss = 0.6431\n",
            "Epoch 28, 1800/2675, Current Loss = 0.6361\n",
            "Epoch 28, 1900/2675, Current Loss = 0.6163\n",
            "Epoch 28, 2000/2675, Current Loss = 0.6999\n",
            "Epoch 28, 2100/2675, Current Loss = 0.6560\n",
            "Epoch 28, 2200/2675, Current Loss = 0.6465\n",
            "Epoch 28, 2300/2675, Current Loss = 0.6396\n",
            "Epoch 28, 2400/2675, Current Loss = 0.6442\n",
            "Epoch 28, 2500/2675, Current Loss = 0.6566\n",
            "Epoch 28, 2600/2675, Current Loss = 0.6561\n",
            "Epoch 29, 0/2675, Current Loss = 0.4836\n",
            "Epoch 29, 100/2675, Current Loss = 0.5642\n",
            "Epoch 29, 200/2675, Current Loss = 0.5457\n",
            "Epoch 29, 300/2675, Current Loss = 0.5377\n",
            "Epoch 29, 400/2675, Current Loss = 0.5458\n",
            "Epoch 29, 500/2675, Current Loss = 0.5723\n",
            "Epoch 29, 600/2675, Current Loss = 0.5904\n",
            "Epoch 29, 700/2675, Current Loss = 0.5837\n",
            "Epoch 29, 800/2675, Current Loss = 0.5628\n",
            "Epoch 29, 900/2675, Current Loss = 0.5552\n",
            "Epoch 29, 1000/2675, Current Loss = 0.5737\n",
            "Epoch 29, 1100/2675, Current Loss = 0.6027\n",
            "Epoch 29, 1200/2675, Current Loss = 0.5546\n",
            "Epoch 29, 1300/2675, Current Loss = 0.6102\n",
            "Epoch 29, 1400/2675, Current Loss = 0.5882\n",
            "Epoch 29, 1500/2675, Current Loss = 0.6304\n",
            "Epoch 29, 1600/2675, Current Loss = 0.6011\n",
            "Epoch 29, 1700/2675, Current Loss = 0.5753\n",
            "Epoch 29, 1800/2675, Current Loss = 0.6112\n",
            "Epoch 29, 1900/2675, Current Loss = 0.5788\n",
            "Epoch 29, 2000/2675, Current Loss = 0.5894\n",
            "Epoch 29, 2100/2675, Current Loss = 0.5859\n",
            "Epoch 29, 2200/2675, Current Loss = 0.6515\n",
            "Epoch 29, 2300/2675, Current Loss = 0.5928\n",
            "Epoch 29, 2400/2675, Current Loss = 0.6046\n",
            "Epoch 29, 2500/2675, Current Loss = 0.6368\n",
            "Epoch 29, 2600/2675, Current Loss = 0.6121\n",
            "Epoch 30, 0/2675, Current Loss = 0.4630\n",
            "Epoch 30, 100/2675, Current Loss = 0.5297\n",
            "Epoch 30, 200/2675, Current Loss = 0.5384\n",
            "Epoch 30, 300/2675, Current Loss = 0.4795\n",
            "Epoch 30, 400/2675, Current Loss = 0.5202\n",
            "Epoch 30, 500/2675, Current Loss = 0.5163\n",
            "Epoch 30, 600/2675, Current Loss = 0.5062\n",
            "Epoch 30, 700/2675, Current Loss = 0.5722\n",
            "Epoch 30, 800/2675, Current Loss = 0.5691\n",
            "Epoch 30, 900/2675, Current Loss = 0.5656\n",
            "Epoch 30, 1000/2675, Current Loss = 0.5619\n",
            "Epoch 30, 1100/2675, Current Loss = 0.5425\n",
            "Epoch 30, 1200/2675, Current Loss = 0.5723\n",
            "Epoch 30, 1300/2675, Current Loss = 0.5440\n",
            "Epoch 30, 1400/2675, Current Loss = 0.5636\n",
            "Epoch 30, 1500/2675, Current Loss = 0.5403\n",
            "Epoch 30, 1600/2675, Current Loss = 0.5628\n",
            "Epoch 30, 1700/2675, Current Loss = 0.5360\n",
            "Epoch 30, 1800/2675, Current Loss = 0.5827\n",
            "Epoch 30, 1900/2675, Current Loss = 0.5673\n",
            "Epoch 30, 2000/2675, Current Loss = 0.5729\n",
            "Epoch 30, 2100/2675, Current Loss = 0.5583\n",
            "Epoch 30, 2200/2675, Current Loss = 0.5587\n",
            "Epoch 30, 2300/2675, Current Loss = 0.6211\n",
            "Epoch 30, 2400/2675, Current Loss = 0.5462\n",
            "Epoch 30, 2500/2675, Current Loss = 0.5808\n",
            "Epoch 30, 2600/2675, Current Loss = 0.5917\n",
            "Epoch 31, 0/2675, Current Loss = 0.4280\n",
            "Epoch 31, 100/2675, Current Loss = 0.4590\n",
            "Epoch 31, 200/2675, Current Loss = 0.4968\n",
            "Epoch 31, 300/2675, Current Loss = 0.5133\n",
            "Epoch 31, 400/2675, Current Loss = 0.4878\n",
            "Epoch 31, 500/2675, Current Loss = 0.4942\n",
            "Epoch 31, 600/2675, Current Loss = 0.4948\n",
            "Epoch 31, 700/2675, Current Loss = 0.4925\n",
            "Epoch 31, 800/2675, Current Loss = 0.5224\n",
            "Epoch 31, 900/2675, Current Loss = 0.4981\n",
            "Epoch 31, 1000/2675, Current Loss = 0.5134\n",
            "Epoch 31, 1100/2675, Current Loss = 0.5431\n",
            "Epoch 31, 1200/2675, Current Loss = 0.5222\n",
            "Epoch 31, 1300/2675, Current Loss = 0.5130\n",
            "Epoch 31, 1400/2675, Current Loss = 0.5095\n",
            "Epoch 31, 1500/2675, Current Loss = 0.5592\n",
            "Epoch 31, 1600/2675, Current Loss = 0.5430\n",
            "Epoch 31, 1700/2675, Current Loss = 0.5213\n",
            "Epoch 31, 1800/2675, Current Loss = 0.5719\n",
            "Epoch 31, 1900/2675, Current Loss = 0.5394\n",
            "Epoch 31, 2000/2675, Current Loss = 0.5079\n",
            "Epoch 31, 2100/2675, Current Loss = 0.5634\n",
            "Epoch 31, 2200/2675, Current Loss = 0.5658\n",
            "Epoch 31, 2300/2675, Current Loss = 0.5534\n",
            "Epoch 31, 2400/2675, Current Loss = 0.5472\n",
            "Epoch 31, 2500/2675, Current Loss = 0.5333\n",
            "Epoch 31, 2600/2675, Current Loss = 0.5414\n",
            "Epoch 32, 0/2675, Current Loss = 0.3801\n",
            "Epoch 32, 100/2675, Current Loss = 0.4565\n",
            "Epoch 32, 200/2675, Current Loss = 0.4621\n",
            "Epoch 32, 300/2675, Current Loss = 0.4689\n",
            "Epoch 32, 400/2675, Current Loss = 0.4751\n",
            "Epoch 32, 500/2675, Current Loss = 0.4380\n",
            "Epoch 32, 600/2675, Current Loss = 0.4917\n",
            "Epoch 32, 700/2675, Current Loss = 0.4418\n",
            "Epoch 32, 800/2675, Current Loss = 0.4696\n",
            "Epoch 32, 900/2675, Current Loss = 0.5024\n",
            "Epoch 32, 1000/2675, Current Loss = 0.4972\n",
            "Epoch 32, 1100/2675, Current Loss = 0.4503\n",
            "Epoch 32, 1200/2675, Current Loss = 0.5208\n",
            "Epoch 32, 1300/2675, Current Loss = 0.4833\n",
            "Epoch 32, 1400/2675, Current Loss = 0.4928\n",
            "Epoch 32, 1500/2675, Current Loss = 0.4781\n",
            "Epoch 32, 1600/2675, Current Loss = 0.4897\n",
            "Epoch 32, 1700/2675, Current Loss = 0.4843\n",
            "Epoch 32, 1800/2675, Current Loss = 0.5348\n",
            "Epoch 32, 1900/2675, Current Loss = 0.5189\n",
            "Epoch 32, 2000/2675, Current Loss = 0.5153\n",
            "Epoch 32, 2100/2675, Current Loss = 0.5203\n",
            "Epoch 32, 2200/2675, Current Loss = 0.5426\n",
            "Epoch 32, 2300/2675, Current Loss = 0.4836\n",
            "Epoch 32, 2400/2675, Current Loss = 0.5259\n",
            "Epoch 32, 2500/2675, Current Loss = 0.5325\n",
            "Epoch 32, 2600/2675, Current Loss = 0.5310\n",
            "Epoch 33, 0/2675, Current Loss = 0.3960\n",
            "Epoch 33, 100/2675, Current Loss = 0.4429\n",
            "Epoch 33, 200/2675, Current Loss = 0.4573\n",
            "Epoch 33, 300/2675, Current Loss = 0.4241\n",
            "Epoch 33, 400/2675, Current Loss = 0.4172\n",
            "Epoch 33, 500/2675, Current Loss = 0.4178\n",
            "Epoch 33, 600/2675, Current Loss = 0.4559\n",
            "Epoch 33, 700/2675, Current Loss = 0.4549\n",
            "Epoch 33, 800/2675, Current Loss = 0.4835\n",
            "Epoch 33, 900/2675, Current Loss = 0.4497\n",
            "Epoch 33, 1000/2675, Current Loss = 0.4668\n",
            "Epoch 33, 1100/2675, Current Loss = 0.4750\n",
            "Epoch 33, 1200/2675, Current Loss = 0.4525\n",
            "Epoch 33, 1300/2675, Current Loss = 0.4893\n",
            "Epoch 33, 1400/2675, Current Loss = 0.4641\n",
            "Epoch 33, 1500/2675, Current Loss = 0.4622\n",
            "Epoch 33, 1600/2675, Current Loss = 0.4448\n",
            "Epoch 33, 1700/2675, Current Loss = 0.5036\n",
            "Epoch 33, 1800/2675, Current Loss = 0.4735\n",
            "Epoch 33, 1900/2675, Current Loss = 0.4555\n",
            "Epoch 33, 2000/2675, Current Loss = 0.4802\n",
            "Epoch 33, 2100/2675, Current Loss = 0.4902\n",
            "Epoch 33, 2200/2675, Current Loss = 0.4979\n",
            "Epoch 33, 2300/2675, Current Loss = 0.5050\n",
            "Epoch 33, 2400/2675, Current Loss = 0.4834\n",
            "Epoch 33, 2500/2675, Current Loss = 0.5012\n",
            "Epoch 33, 2600/2675, Current Loss = 0.4728\n",
            "Epoch 34, 0/2675, Current Loss = 0.3882\n",
            "Epoch 34, 100/2675, Current Loss = 0.4046\n",
            "Epoch 34, 200/2675, Current Loss = 0.4136\n",
            "Epoch 34, 300/2675, Current Loss = 0.4203\n",
            "Epoch 34, 400/2675, Current Loss = 0.3915\n",
            "Epoch 34, 500/2675, Current Loss = 0.4397\n",
            "Epoch 34, 600/2675, Current Loss = 0.4204\n",
            "Epoch 34, 700/2675, Current Loss = 0.4661\n",
            "Epoch 34, 800/2675, Current Loss = 0.4308\n",
            "Epoch 34, 900/2675, Current Loss = 0.4471\n",
            "Epoch 34, 1000/2675, Current Loss = 0.4405\n",
            "Epoch 34, 1100/2675, Current Loss = 0.4277\n",
            "Epoch 34, 1200/2675, Current Loss = 0.4172\n",
            "Epoch 34, 1300/2675, Current Loss = 0.4142\n",
            "Epoch 34, 1400/2675, Current Loss = 0.4386\n",
            "Epoch 34, 1500/2675, Current Loss = 0.4335\n",
            "Epoch 34, 1600/2675, Current Loss = 0.4358\n",
            "Epoch 34, 1700/2675, Current Loss = 0.4493\n",
            "Epoch 34, 1800/2675, Current Loss = 0.4882\n",
            "Epoch 34, 1900/2675, Current Loss = 0.4585\n",
            "Epoch 34, 2000/2675, Current Loss = 0.4973\n",
            "Epoch 34, 2100/2675, Current Loss = 0.4619\n",
            "Epoch 34, 2200/2675, Current Loss = 0.4587\n",
            "Epoch 34, 2300/2675, Current Loss = 0.4620\n",
            "Epoch 34, 2400/2675, Current Loss = 0.4585\n",
            "Epoch 34, 2500/2675, Current Loss = 0.4711\n",
            "Epoch 34, 2600/2675, Current Loss = 0.4696\n",
            "Epoch 35, 0/2675, Current Loss = 0.3560\n",
            "Epoch 35, 100/2675, Current Loss = 0.4011\n",
            "Epoch 35, 200/2675, Current Loss = 0.3887\n",
            "Epoch 35, 300/2675, Current Loss = 0.3759\n",
            "Epoch 35, 400/2675, Current Loss = 0.3843\n",
            "Epoch 35, 500/2675, Current Loss = 0.3995\n",
            "Epoch 35, 600/2675, Current Loss = 0.3709\n",
            "Epoch 35, 700/2675, Current Loss = 0.4449\n",
            "Epoch 35, 800/2675, Current Loss = 0.4041\n",
            "Epoch 35, 900/2675, Current Loss = 0.4293\n",
            "Epoch 35, 1000/2675, Current Loss = 0.4200\n",
            "Epoch 35, 1100/2675, Current Loss = 0.4350\n",
            "Epoch 35, 1200/2675, Current Loss = 0.4177\n",
            "Epoch 35, 1300/2675, Current Loss = 0.4224\n",
            "Epoch 35, 1400/2675, Current Loss = 0.4040\n",
            "Epoch 35, 1500/2675, Current Loss = 0.4313\n",
            "Epoch 35, 1600/2675, Current Loss = 0.4530\n",
            "Epoch 35, 1700/2675, Current Loss = 0.4414\n",
            "Epoch 35, 1800/2675, Current Loss = 0.4449\n",
            "Epoch 35, 1900/2675, Current Loss = 0.4389\n",
            "Epoch 35, 2000/2675, Current Loss = 0.4257\n",
            "Epoch 35, 2100/2675, Current Loss = 0.3999\n",
            "Epoch 35, 2200/2675, Current Loss = 0.4634\n",
            "Epoch 35, 2300/2675, Current Loss = 0.4335\n",
            "Epoch 35, 2400/2675, Current Loss = 0.4489\n",
            "Epoch 35, 2500/2675, Current Loss = 0.4445\n",
            "Epoch 35, 2600/2675, Current Loss = 0.4391\n",
            "Epoch 36, 0/2675, Current Loss = 0.3443\n",
            "Epoch 36, 100/2675, Current Loss = 0.3640\n",
            "Epoch 36, 200/2675, Current Loss = 0.3711\n",
            "Epoch 36, 300/2675, Current Loss = 0.3827\n",
            "Epoch 36, 400/2675, Current Loss = 0.3585\n",
            "Epoch 36, 500/2675, Current Loss = 0.3788\n",
            "Epoch 36, 600/2675, Current Loss = 0.3833\n",
            "Epoch 36, 700/2675, Current Loss = 0.4499\n",
            "Epoch 36, 800/2675, Current Loss = 0.3904\n",
            "Epoch 36, 900/2675, Current Loss = 0.4048\n",
            "Epoch 36, 1000/2675, Current Loss = 0.3794\n",
            "Epoch 36, 1100/2675, Current Loss = 0.4031\n",
            "Epoch 36, 1200/2675, Current Loss = 0.3957\n",
            "Epoch 36, 1300/2675, Current Loss = 0.4349\n",
            "Epoch 36, 1400/2675, Current Loss = 0.3789\n",
            "Epoch 36, 1500/2675, Current Loss = 0.4121\n",
            "Epoch 36, 1600/2675, Current Loss = 0.4211\n",
            "Epoch 36, 1700/2675, Current Loss = 0.4270\n",
            "Epoch 36, 1800/2675, Current Loss = 0.4062\n",
            "Epoch 36, 1900/2675, Current Loss = 0.3881\n",
            "Epoch 36, 2000/2675, Current Loss = 0.4018\n",
            "Epoch 36, 2100/2675, Current Loss = 0.4331\n",
            "Epoch 36, 2200/2675, Current Loss = 0.4385\n",
            "Epoch 36, 2300/2675, Current Loss = 0.4297\n",
            "Epoch 36, 2400/2675, Current Loss = 0.4467\n",
            "Epoch 36, 2500/2675, Current Loss = 0.4160\n",
            "Epoch 36, 2600/2675, Current Loss = 0.4183\n",
            "Epoch 37, 0/2675, Current Loss = 0.2990\n",
            "Epoch 37, 100/2675, Current Loss = 0.3404\n",
            "Epoch 37, 200/2675, Current Loss = 0.3383\n",
            "Epoch 37, 300/2675, Current Loss = 0.3931\n",
            "Epoch 37, 400/2675, Current Loss = 0.3541\n",
            "Epoch 37, 500/2675, Current Loss = 0.4002\n",
            "Epoch 37, 600/2675, Current Loss = 0.3681\n",
            "Epoch 37, 700/2675, Current Loss = 0.3461\n",
            "Epoch 37, 800/2675, Current Loss = 0.3666\n",
            "Epoch 37, 900/2675, Current Loss = 0.3564\n",
            "Epoch 37, 1000/2675, Current Loss = 0.3947\n",
            "Epoch 37, 1100/2675, Current Loss = 0.3873\n",
            "Epoch 37, 1200/2675, Current Loss = 0.3819\n",
            "Epoch 37, 1300/2675, Current Loss = 0.4057\n",
            "Epoch 37, 1400/2675, Current Loss = 0.3979\n",
            "Epoch 37, 1500/2675, Current Loss = 0.3866\n",
            "Epoch 37, 1600/2675, Current Loss = 0.3759\n",
            "Epoch 37, 1700/2675, Current Loss = 0.3703\n",
            "Epoch 37, 1800/2675, Current Loss = 0.4070\n",
            "Epoch 37, 1900/2675, Current Loss = 0.4195\n",
            "Epoch 37, 2000/2675, Current Loss = 0.4163\n",
            "Epoch 37, 2100/2675, Current Loss = 0.3984\n",
            "Epoch 37, 2200/2675, Current Loss = 0.4109\n",
            "Epoch 37, 2300/2675, Current Loss = 0.3853\n",
            "Epoch 37, 2400/2675, Current Loss = 0.4322\n",
            "Epoch 37, 2500/2675, Current Loss = 0.4001\n",
            "Epoch 37, 2600/2675, Current Loss = 0.3742\n",
            "Epoch 38, 0/2675, Current Loss = 0.3003\n",
            "Epoch 38, 100/2675, Current Loss = 0.3654\n",
            "Epoch 38, 200/2675, Current Loss = 0.3617\n",
            "Epoch 38, 300/2675, Current Loss = 0.3538\n",
            "Epoch 38, 400/2675, Current Loss = 0.3677\n",
            "Epoch 38, 500/2675, Current Loss = 0.3540\n",
            "Epoch 38, 600/2675, Current Loss = 0.3268\n",
            "Epoch 38, 700/2675, Current Loss = 0.3567\n",
            "Epoch 38, 800/2675, Current Loss = 0.3285\n",
            "Epoch 38, 900/2675, Current Loss = 0.3532\n",
            "Epoch 38, 1000/2675, Current Loss = 0.3487\n",
            "Epoch 38, 1100/2675, Current Loss = 0.3915\n",
            "Epoch 38, 1200/2675, Current Loss = 0.3639\n",
            "Epoch 38, 1300/2675, Current Loss = 0.3745\n",
            "Epoch 38, 1400/2675, Current Loss = 0.3674\n",
            "Epoch 38, 1500/2675, Current Loss = 0.3671\n",
            "Epoch 38, 1600/2675, Current Loss = 0.4008\n",
            "Epoch 38, 1700/2675, Current Loss = 0.4041\n",
            "Epoch 38, 1800/2675, Current Loss = 0.3703\n",
            "Epoch 38, 1900/2675, Current Loss = 0.4048\n",
            "Epoch 38, 2000/2675, Current Loss = 0.3849\n",
            "Epoch 38, 2100/2675, Current Loss = 0.3803\n",
            "Epoch 38, 2200/2675, Current Loss = 0.3984\n",
            "Epoch 38, 2300/2675, Current Loss = 0.3879\n",
            "Epoch 38, 2400/2675, Current Loss = 0.3900\n",
            "Epoch 38, 2500/2675, Current Loss = 0.3797\n",
            "Epoch 38, 2600/2675, Current Loss = 0.3965\n",
            "Epoch 39, 0/2675, Current Loss = 0.2693\n",
            "Epoch 39, 100/2675, Current Loss = 0.3477\n",
            "Epoch 39, 200/2675, Current Loss = 0.3335\n",
            "Epoch 39, 300/2675, Current Loss = 0.3276\n",
            "Epoch 39, 400/2675, Current Loss = 0.3220\n",
            "Epoch 39, 500/2675, Current Loss = 0.3244\n",
            "Epoch 39, 600/2675, Current Loss = 0.3169\n",
            "Epoch 39, 700/2675, Current Loss = 0.3351\n",
            "Epoch 39, 800/2675, Current Loss = 0.3293\n",
            "Epoch 39, 900/2675, Current Loss = 0.3570\n",
            "Epoch 39, 1000/2675, Current Loss = 0.3363\n",
            "Epoch 39, 1100/2675, Current Loss = 0.3765\n",
            "Epoch 39, 1200/2675, Current Loss = 0.3724\n",
            "Epoch 39, 1300/2675, Current Loss = 0.3398\n",
            "Epoch 39, 1400/2675, Current Loss = 0.3512\n",
            "Epoch 39, 1500/2675, Current Loss = 0.3385\n",
            "Epoch 39, 1600/2675, Current Loss = 0.3346\n",
            "Epoch 39, 1700/2675, Current Loss = 0.3500\n",
            "Epoch 39, 1800/2675, Current Loss = 0.3998\n",
            "Epoch 39, 1900/2675, Current Loss = 0.3924\n",
            "Epoch 39, 2000/2675, Current Loss = 0.3776\n",
            "Epoch 39, 2100/2675, Current Loss = 0.3636\n",
            "Epoch 39, 2200/2675, Current Loss = 0.3925\n",
            "Epoch 39, 2300/2675, Current Loss = 0.3481\n",
            "Epoch 39, 2400/2675, Current Loss = 0.3566\n",
            "Epoch 39, 2500/2675, Current Loss = 0.4064\n",
            "Epoch 39, 2600/2675, Current Loss = 0.3981\n",
            "Epoch 40, 0/2675, Current Loss = 0.3051\n",
            "Epoch 40, 100/2675, Current Loss = 0.2667\n",
            "Epoch 40, 200/2675, Current Loss = 0.3471\n",
            "Epoch 40, 300/2675, Current Loss = 0.3184\n",
            "Epoch 40, 400/2675, Current Loss = 0.3336\n",
            "Epoch 40, 500/2675, Current Loss = 0.3130\n",
            "Epoch 40, 600/2675, Current Loss = 0.3341\n",
            "Epoch 40, 700/2675, Current Loss = 0.3313\n",
            "Epoch 40, 800/2675, Current Loss = 0.3433\n",
            "Epoch 40, 900/2675, Current Loss = 0.3393\n",
            "Epoch 40, 1000/2675, Current Loss = 0.3388\n",
            "Epoch 40, 1100/2675, Current Loss = 0.3674\n",
            "Epoch 40, 1200/2675, Current Loss = 0.3623\n",
            "Epoch 40, 1300/2675, Current Loss = 0.3402\n",
            "Epoch 40, 1400/2675, Current Loss = 0.3404\n",
            "Epoch 40, 1500/2675, Current Loss = 0.3918\n",
            "Epoch 40, 1600/2675, Current Loss = 0.3434\n",
            "Epoch 40, 1700/2675, Current Loss = 0.3866\n",
            "Epoch 40, 1800/2675, Current Loss = 0.3579\n",
            "Epoch 40, 1900/2675, Current Loss = 0.4097\n",
            "Epoch 40, 2000/2675, Current Loss = 0.3643\n",
            "Epoch 40, 2100/2675, Current Loss = 0.3499\n",
            "Epoch 40, 2200/2675, Current Loss = 0.3818\n",
            "Epoch 40, 2300/2675, Current Loss = 0.3556\n",
            "Epoch 40, 2400/2675, Current Loss = 0.3678\n",
            "Epoch 40, 2500/2675, Current Loss = 0.3216\n",
            "Epoch 40, 2600/2675, Current Loss = 0.3527\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VQgar26iOfWB",
        "colab_type": "text"
      },
      "source": [
        "# Generation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ASB64FvOez4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate(model, vocab, start_string, temperature, max_len):\n",
        "    '''\n",
        "    This function gets a trained model and vocab and generates a random string\n",
        "    using the model, seeded with the start_string string.\n",
        "    The temparature value is used to generate a more diverse output (high value),\n",
        "    then a conservative one (low value).\n",
        "    '''\n",
        "    str = start_string\n",
        "    sequence = vocab.index_sentence(start_string)\n",
        "        \n",
        "    # remove the EOS, we don't need it for generation\n",
        "    sequence = sequence[:-1]\n",
        "    \n",
        "    hidden = model.init_hidden()\n",
        "    sequence_ten = torch.LongTensor(sequence).cuda()\n",
        "    for i in range(len(sequence_ten) - 1):\n",
        "      _, hidden = model(sequence_ten[i], hidden)\n",
        "      \n",
        "    output, hidden = model(sequence_ten[-1], hidden) \n",
        "    out_dist = output.view(-1).div(temperature).exp()\n",
        "    new_c = vocab.id2char[torch.multinomial(out_dist, 1)[0].item()]\n",
        "    str += new_c\n",
        "    for i in range(max_len):\n",
        "        new_c_var = torch.LongTensor([vocab.index_char(new_c)]).cuda()\n",
        "        output, hidden = model(new_c_var, hidden)\n",
        "        out_dist = output.view(-1).div(temperature).exp()\n",
        "        char_id = torch.multinomial(out_dist, 1)[0].item()\n",
        "        if char_id == EOS_TOKEN:\n",
        "            return str\n",
        "        new_c = vocab.id2char[char_id]\n",
        "        str += new_c\n",
        "    return str"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Y3H-BBJ41UZ",
        "colab_type": "code",
        "outputId": "5aa9f206-6465-462b-feb1-f5e9ffd282d6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "for i in range(200):\n",
        "    print(generate(model, vocab, 'I got ', 1, 200))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "I got me a tan lil italian thang for acuration.  https://t.co/qzqhbvnnyq\n",
            "I got his hair some efciouse not\n",
            "I got a new urban only in the projest good people ling...ips. thange.\n",
            "I got any of these https://t.co/n1vn6ue6jq\n",
            "I got one new the new up son\n",
            "I got a new jersey https://t.co/jnrx1klbrd\n",
            "I got any of the day, ready to fuck just coppins in tradaduphed - @jodanceleri great, i’m literally hours and we’ve already park nobada\n",
            "I got my about to out 😭\n",
            "I got any of these https://t.co/uar35kmcjw\n",
            "I got me a tan lil itmal. like im know😂\n",
            "I got a new esnow forget https://t.co/oww9lxhxw7\n",
            "I got hair stopped and go let’s hope it’s of my thing\n",
            "I got an each on my more than this one of that.\n",
            "I got me a feliz navidad y’all know\n",
            "I got any of the dayfice.\n",
            "I got an extra special patching!\n",
            "I got any of these https://t.co/ri2e59jcxo\n",
            "I got me a tan lil italainum. go have thema\n",
            "I got you an the anightm\n",
            "I got any of their wouldn't beautiful. it’s like today!! enjoy the day\n",
            "I got a new urban x nonesh vida you parents game someone’s my my house?\n",
            "I got me a tan lil italian thang for christmas\n",
            "I got chat. @ new york, new york https://t.co/ouwwwc1xri\n",
            "I got any of the hus!❤️❤️❤️\n",
            "I got a new shopped\n",
            "I got ? at?\n",
            "I got the bread.\n",
            "I got me and my man, my little hills reauding my old of holiday 😅\n",
            "I got the 25th daymon\n",
            "I got a thing\n",
            "I got any of these are had damn\n",
            "I got changer now i got to see and had me too\n",
            "I got his more since #themselves #myemojive, https://t.co/mqmldsyrxi\n",
            "I got you anjered me no feet. 😂😂\n",
            "I got me a tan lil italaus to all 😘\n",
            "I got be have me drew me no dead one\n",
            "I got the netciou\n",
            "\n",
            "\n",
            "thankfast 4 deserves it\n",
            "I got me a nintendo 30 at me gor not girl that’s med\n",
            "I got one and need to get my egirl navidad\n",
            "I got a new urna of the top. 😩\n",
            "I got a the ofe here.\n",
            "I got a great wait to go on that\n",
            "I got an extra $100 today for being single\n",
            "I got an enstrow on #morthereste/loveth #fagirstonbrandlade @ new jersey https://t.co/kp6saun6je\n",
            "I got any of these https://t.co/p3e68frexc\n",
            "I got an extra $100 today for being single\n",
            "I got a new urban (2 anny not one even world tod.\n",
            "I got a new urp right?\n",
            "I got me a nintendo 3ds and animal corsed go one of them have a happy nine who even judea. 😍😍\n",
            "I got the 5 on the neight 😂😂\n",
            "I got me and my mom and my mom not american mostat. today?\n",
            "I got me a new york\n",
            "I got 5 on christmas sprit @sonardesift\n",
            "I got any of the husired!\n",
            "I got any of the askwarm... que nos ade. #christmasdincerdat #merry 🙏🏾🎄❤️❤️htwas https://t.co/pn3z6krt4c\n",
            "I got a christmas x locarabiés 🎄🎁 https://t.co/o826we2vxt1\n",
            "I got an extra $300 to ade. i go ch\n",
            "I got having a gift canada! - @wuzredpricks @sonfindaldsjdes https://t.co/xlxqs43ntq\n",
            "I got any of theire photogreat\n",
            "I got any of the hardcars\n",
            "I got any ofe the white how dremb it loss \n",
            "https://t.co/bj97jb73wh\n",
            "I got ane u little 3pd frendly fucking just beautiful...\n",
            "I got the ocean in ny\n",
            "I got the #knicksman coudity, schunhwish, kaw!!\n",
            "I got a new esman must’s happer done would them too\n",
            "I got many foundation on today😬\n",
            "I got a new extra $size 100% just beautiful.\n",
            "I got a jersey https://t.co/vnbcz3ffd\n",
            "I got an extra $100 today. sole...y. thank for tom of them\n",
            "I got 1 today for being unhautiful gifts up? https://t.co/o3zrdgxpqg\n",
            "I got an extra $100 today for being single\n",
            "I got you an emoji have to my favorite played. thank you m.\n",
            "I got a new urst and pro sen world ble\n",
            "I got any ofe here \n",
            "\n",
            "home!\n",
            "home have to my two aesthetics meet 🎄🎁 https://t.co/lnnopxutql\n",
            "I got an extra $ duagranch in new york, ny w/ yee https://t.co/p4rkshfjre\n",
            "I got me a tan trailty do. #👏👏👏👏👏\n",
            "I got one dester”!! @ long, scare everyone https://t.co/4yvbiqwifl\n",
            "I got a new jersey https://t.co/nigknlwne\n",
            "I got his into ne people still turn lime. ❤️ thanksjuist\n",
            "I got can asouts 2018 todays off watch merry knife x @ new jersey https://t.co/eivnlbhm5n\n",
            "I got any of theire\n",
            "I got me a tan lil italian arting my favorite of  drightman dep family today\n",
            "I got a christmas &amp; my navida\n",
            "I got an extra perities \"thire life 🔥🎁 o\n",
            "I got an extra $30 good like thank\n",
            "I got 5 on at me.\n",
            "I got any of these https://t.co/noz7lxu2k6\n",
            "I got you anna extra $s of 1 grot cother pientive friend!!\n",
            "I got 1 thank god for obad. shitton https://t.co/tptwje8d6a\n",
            "I got an extra $100 today for being singles\n",
            "I got a new espresso mac c next year, my whire https://t.co/jdv0gyrvp6\n",
            "I got hanger\n",
            "I got me a tan lil italagint\n",
            "I got an extra $15th stret 😂\n",
            "I got an extra special holiday!! merry christmas!\n",
            "I got me and my manhattan and being about.” —mom, decrying to hear ya. weh godford me and the real stip!\n",
            "I got a new espress 😂\n",
            "I got 2019 term nine...trash is traduman\n",
            "I got hain for the aquaman in new york, ny w/ @yehuhahahah haha!\n",
            "I got my mans me love! ❤️the havenue and diamal, im staying 😂😷 i’m wantantas\n",
            "I got 5 on attittle today, skew. 😂😂😂😂😂😂😂\n",
            "I got an extra $100 today for being is of freakish 💲/pol this! https://t.co/zw0xyi2wpl\n",
            "I got cheated https://t.co/nozkj4hwf\n",
            "I got chat to 700” — have you my my modmy\n",
            "I got the 5 of this” #bblack, new york https://t.co/wuj3rjgiht\n",
            "I got me a tan lil italian thang grow and you're put skip 😂\n",
            "I got an extra $100 today fore his mind the rockets of beding about the us.\n",
            "I got a extra $100 told me ‘oool town posisting, ny) https://t.co/mn4zrwtsho\n",
            "I got one and dead. quinterned vai same exactly. ❤️ #homealynu2 thanks for them\n",
            "I got any of these https://t.co/jltrx50pl\n",
            "I got 5 on an aquia x! gannawa\n",
            "I got any of these this\n",
            "I got me a talk that’s even afready kimples #teemojiveolone\n",
            "I got any of these 🤷🏻‍♀️\n",
            "I got you anna extrañ 🎄 @ like watch, wanna watch #brokendona job nex to gonn to and try an eash in güendo 😊\n",
            "I got here on the ands.\n",
            "I got antice 😭 https://t.co/n6hukl4bla\n",
            "I got any of these https://t.co/cvpqhuo8tz\n",
            "I got any of the daid!\n",
            "I got on elsed get on peterthe, movie dragment.\n",
            "I got one delierican coldan’s xmas dinner today. 😘😍\n",
            "I got mine today.\n",
            "I got checking for the flowes gart https://t.co/gpybuihq6k\n",
            "I got me a tan lill talls that\n",
            "I got a nearly who every hit, i'll this holiday pay so this problem that.\n",
            "I got you anna extra $201 at another pieson 😊 @ manhattan, new york city https://t.co/2eb9y9r5jc\n",
            "I got the categ of 2018! thank you\n",
            "I got a vice. well this on the things i hap enjoy the damn start and but is this, even after the best\n",
            "I got chate?!?!? ?\n",
            "I got me a nintendo 3ds and and phantan\n",
            "I got a extra $100 today for being about my wigh?\n",
            "I got any of these\n",
            "I got a new espressor gets only 😂\n",
            "I got me and pele to my enug https://t.co/4yxdwrcrel\n",
            "I got the 25th? today\n",
            "I got 5 on at my tweater with that\n",
            "I got manhattan and bew gross for seving piestor! \n",
            "😍 https://t.co/vqhct8mpnq\n",
            "I got any of them\n",
            "I got any of the team!!\n",
            "I got 2019 form the agrening... its can do forget of them\n",
            "I got an eat on #theirsestonblack https://t.co/vqlc1xjdoz\n",
            "I got an extra $100 some, vibe stopping sinelf game is have my two earnsined what's the #instonmoviech 😭\n",
            "I got an extra &amp; then theak\n",
            "I got another one\n",
            "I got a excited know that hopishact.\n",
            "I got an extra $100 today for being single\n",
            "I got another off syrian #backline @ norw\n",
            "I got 5 on at my table.\n",
            "I got the ppl be more\n",
            "I got the stopped weird food”\n",
            "I got energy god on the team next year. the for them party need to to. 😊\n",
            "I got any of the time!\n",
            "I got have a great ruiness -ruant, new york, new york https://t.co/ybqd635js4\n",
            "I got any of these that.\n",
            "I got the #cunningnowa bro and nitest https://t.co/mxxqclr4ho\n",
            "I got a new jerse 😂😂, i aman citer that hisma\n",
            "I got a white put me on the meme of her! https://t.co/vn6hpn40fy\n",
            "I got anyone to one of them trea\n",
            "I got any of these https://t.co/oeb9lt40qo\n",
            "I got any of the heard\n",
            "I got a exit 2 - @amctheaters brok https://t.co/nckm6v0tnl\n",
            "I got 5 on attan life 😂\n",
            "I got hang i even together\n",
            "I got at export too merry https://t.co/dcdtru5il9\n",
            "I got have 🔥\n",
            "I got an eathing on here still not jacking that gettenday. thank you ma, you smate.\n",
            "I got the categoring🙄 🎄#homealone https://t.co/ecbmjqkfil\n",
            "I got one today.\n",
            "I got any of these that’s! he of them in perf. 19 proposa\n",
            "I got any of the house?\n",
            "I got hang i amorely not a christmas\n",
            "I got my can attar\n",
            "I got a new espre-soon at christmas and ide. https://t.co/9p6u67cent\n",
            "I got new more burkel\n",
            "I got a new york.\n",
            "I got an extra $100 today for being ushise the just super was $100 of u d\n",
            "I got any of these christmas &amp; 🏀 merry christmas ! https://t.co/vnfmfnxdq\n",
            "I got an extra $100 today for being single\n",
            "I got any form ozorie of them\n",
            "I got me a tan liltol\n",
            "I got an extra $100 today for being single\n",
            "I got any of the human #25thamendment #25thamendmentn #25thamendmentn #raiderofline franchise\n",
            "5 @ norklintbark i need to eary https://t.co/tdeyt2gj5x\n",
            "I got i awordson. god bless vik https://t.co/a3thuor1g5\n",
            "I got me a tan lil italian thang for my cousin dannywar - @chefleen https://t.co/8nfaamn73v\n",
            "I got me and the skitch how much of a year with you park boy. ☹️\n",
            "I got queen no to mork today.....\n",
            "I got 2 - kanway for it's ...\n",
            "I got any of the 70”s everyday, when wypp wele pull appreciated! merry christmas my friend’ me very https://t.co/dpjd6knwzx\n",
            "I got my mans me no dawg mi.\n",
            "I got 5 on at my takely\n",
            "I got a new from rule is having me a beggrapher\n",
            ". https://t.co/upus95jcxto\n",
            "I got any of the kids\n",
            "\n",
            "mer: https://t.co/9pinzl4bfa\n",
            "I got any of the mean?\n",
            "I got any of the hugs 523dmas for for an inted in out!!!\n",
            "I got me a nintendo 3ds and and i didnal. do therem music// ...alltunfat\n",
            "I got the catemone since the vago san and smothing\n",
            "I got cheappy saying @jetblue!!!lorneth #grine thank bet, but i'! 😍\n",
            "I got me a tan lil tamble\n",
            "I got any of the according to your morning 🤷🏻‍♂️\n",
            "I got any of these in the match, good to transhing\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}